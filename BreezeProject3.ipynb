{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bfc27289-1262-4a04-9693-f4555ee10b9f",
   "metadata": {},
   "source": [
    "# Project 3 - Supervised Learning and Modeling  \n",
    "\n",
    "Kelley Breeze\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446ac5e8-0fd1-4b5e-bf9b-da434b80a6ee",
   "metadata": {},
   "source": [
    "# Introduction  \n",
    "\n",
    "In this project we will walk through how to use supervised learning to build models in order to predict responses from our dataset. Before we get started let's go over a little bit about what supervised learning is, what we want to do with our models, and briefly discuss the dataset that we will be using throughout the project.\n",
    "\n",
    "### Supervised Learning  \n",
    "In supervised learning you have a response variable that you are trying to predict. If we fit a predictive model using supervised learning it will be possible to evaluate how well our model predicts the value of our response variable by using observations that were not used in fitting our model.\n",
    "\n",
    "### Absenteeism At Work Dataset  \n",
    "\n",
    "The dataset that we will use contains information about absenteeism at a courier company in Brazil from July 2007 to July 2010. This dataset is from the UC Irvine Machine Learning Repository and can be found [here](https://archive-beta.ics.uci.edu/dataset/445/absenteeism+at+work). It contains 21 variables that are detailed below:  \n",
    "\n",
    "1.  `ID` - **Categorical** - Individual Identification - There are 36 unique employees in the dataset. *This variable will be dropped prior to model building*\n",
    "2.  `Reason for absence` - **Categorical** - This is the recorded reason for the employee's absence. This is a categorical variable with 28 total levels that has been coded numerically. The values 1-21, corresponding to I through XXI, are taken from the World Health Organization's [International Statistical Classification of Diseases and Related Helth Problems 10 Revision](https://icd.who.int/browse10/2010/en#/). The remaining 7 values of this variable are:  \n",
    "    -  `22` - patient follow-up  \n",
    "    -  `23` - medical consultaion  \n",
    "    -  `24` - blood donation  \n",
    "    -  `25` - laboratory examination  \n",
    "    -  `26` - unjustified absence  \n",
    "    -  `27` - phisiotherapy  \n",
    "    -  `28` - dental consulation  \n",
    "    \n",
    "    Note that there are a total of 43 records for which the `Reason for absence` is recorded as `0`. We will simply refer to these as representing a value of `unkonwn` for our `Reason for absence` variable.  \n",
    "3.  `Month of absence` - **Categorical** - This is the month in which the absence is registered.  \n",
    "4.  `Day of the week` - **Categorical** - Work day (Monday through Friday) - Categorical - this is coded numerically with the following values:  \n",
    "    -  `2` - Monday  \n",
    "    -  `3` - Tuesday  \n",
    "    -  `4` - Wednesday  \n",
    "    -  `5` - Thursday  \n",
    "    -  `6` - Friday  \n",
    "5.  `Seasons` - **Categorical** - coded numerically with the following values:  \n",
    "    -  `1` - summer  \n",
    "    -  `2` - autumn  \n",
    "    -  `3` - winter  \n",
    "    -  `4` - spring  \n",
    "6. `Transportation expense` - **Numeric** -  This is the monthly transportation expense of each employee in dollars\n",
    "7. `Distance from Residence to Work` - **Numeric** - This is the distance in kilometers that the employee must travel each day to get to work measured in kilometers.    \n",
    "8. `Service time`  - **Numeric** - the service time of each employee in years.  \n",
    "9.  `Age` - **Numeric** - Age of employee in years.  \n",
    "10. `Work load Average/day` - **Numeric** - This is the average workload per day for the employee, units unknown.  \n",
    "11. `Hit target` - **Numeric** - This is an achievement percentage for periodic goals for each employee.  \n",
    "12. `Disciplinary failure (yes=1; no=0)` - **Categorical** - Binary yes/no about whether the employee recieved a disciplinary warning that month.   \n",
    "13. `Education` - **Categorical/Ordinal** - The highest education level attained by the employee, coded numerically with the following values:  \n",
    "    -  `1` - high school  \n",
    "    -  `2` - graduate  \n",
    "    -  `3` - postgraduate  \n",
    "    -  `4` - master and doctor  \n",
    "14. `Son` - **Numeric** - The total number of children of the employee.  \n",
    "15. `Social drinker` - **Categorical** - This is a binary variable where yes = `1` indicates that the employee is a social drinker and no = `0` indicates that the employee is not a social drinker.  \n",
    "16. `Social smoker`- **Categorical** - This is a binary variable where yes = `1` indicates that the employee is a social smoker and no = `0` indicates that the employee is not a social smoker.    \n",
    "17. `Pet` - **Numeric** - This is the number of pets owned by the employee.  \n",
    "18. `Weight` - ***Numeric** - The employee's weight in kilograms.  \n",
    "19. `Height` - **Numeric** - The employee's height in centimeters.  \n",
    "20. `Body mass index` - **Numeric** - The employee's body mass index. *This variable will be dropped as it is highly correlated with weight and height*   \n",
    "21. `Absenteeism time in hours` - **Numeric** - This is our target variable. `Absenteeism time in hours` is a continuous numeric variable representing the number of hours that an employee was absent for a given instance of missed work.  \n",
    "\n",
    "### Question that we want to answer  \n",
    "\n",
    "Can we predict the number of hours that an employee will be absent based on the personal and work related information for that employee provided in the dataset?  \n",
    "\n",
    "### Modeling Goals  \n",
    "\n",
    "Our goal in working with this dataset is to build and test multiple models to predict the number of absentee hours (variable 21) for an employee based on a subset of the available variables (1-20) listed above. We will use five different modeling techniques to build, train, and test models based on the absenteeism at work dataset. We will then compare our models to one another to determine which model is the best at predicting our response variable. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d34e3c-e4dc-499b-8848-b9ff2bb02e6a",
   "metadata": {},
   "source": [
    "## Starting Spark Session and Reading in Our Data  \n",
    "\n",
    "We will begin by starting our spark session and reading in our data. We will also import `pandas` and `numpy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea4b58ed-da20-46b6-b44d-6b7e7ab505b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f7a4cb7-f701-44c2-8f48-59c664c2a98d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Reason for absence</th>\n",
       "      <th>Month of absence</th>\n",
       "      <th>Day of the week</th>\n",
       "      <th>Seasons</th>\n",
       "      <th>Transportation expense</th>\n",
       "      <th>Distance from Residence to Work</th>\n",
       "      <th>Service time</th>\n",
       "      <th>Age</th>\n",
       "      <th>Work load Average/day</th>\n",
       "      <th>...</th>\n",
       "      <th>Disciplinary failure</th>\n",
       "      <th>Education</th>\n",
       "      <th>Son</th>\n",
       "      <th>Social drinker</th>\n",
       "      <th>Social smoker</th>\n",
       "      <th>Pet</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Height</th>\n",
       "      <th>Body mass index</th>\n",
       "      <th>Absenteeism time in hours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>26</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>289</td>\n",
       "      <td>36</td>\n",
       "      <td>13</td>\n",
       "      <td>33</td>\n",
       "      <td>239.554</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>90</td>\n",
       "      <td>172</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>118</td>\n",
       "      <td>13</td>\n",
       "      <td>18</td>\n",
       "      <td>50</td>\n",
       "      <td>239.554</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>98</td>\n",
       "      <td>178</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>179</td>\n",
       "      <td>51</td>\n",
       "      <td>18</td>\n",
       "      <td>38</td>\n",
       "      <td>239.554</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>89</td>\n",
       "      <td>170</td>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>279</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>39</td>\n",
       "      <td>239.554</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>68</td>\n",
       "      <td>168</td>\n",
       "      <td>24</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>23</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>289</td>\n",
       "      <td>36</td>\n",
       "      <td>13</td>\n",
       "      <td>33</td>\n",
       "      <td>239.554</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>90</td>\n",
       "      <td>172</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>225</td>\n",
       "      <td>26</td>\n",
       "      <td>9</td>\n",
       "      <td>28</td>\n",
       "      <td>306.345</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>69</td>\n",
       "      <td>169</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>289</td>\n",
       "      <td>36</td>\n",
       "      <td>13</td>\n",
       "      <td>33</td>\n",
       "      <td>306.345</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>90</td>\n",
       "      <td>172</td>\n",
       "      <td>30</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>15</td>\n",
       "      <td>23</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>291</td>\n",
       "      <td>31</td>\n",
       "      <td>12</td>\n",
       "      <td>40</td>\n",
       "      <td>306.345</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>73</td>\n",
       "      <td>171</td>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>33</td>\n",
       "      <td>23</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>248</td>\n",
       "      <td>25</td>\n",
       "      <td>14</td>\n",
       "      <td>47</td>\n",
       "      <td>261.306</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>86</td>\n",
       "      <td>165</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>34</td>\n",
       "      <td>19</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>118</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>37</td>\n",
       "      <td>261.306</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>83</td>\n",
       "      <td>172</td>\n",
       "      <td>28</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    ID  Reason for absence  Month of absence  Day of the week  Seasons  \\\n",
       "0   11                  26                 7                3        1   \n",
       "1   36                   0                 7                3        1   \n",
       "2    3                  23                 7                4        1   \n",
       "3    7                   7                 7                5        1   \n",
       "4   11                  23                 7                5        1   \n",
       "..  ..                 ...               ...              ...      ...   \n",
       "95  28                  28                11                3        4   \n",
       "96  11                   7                11                4        4   \n",
       "97  15                  23                11                5        4   \n",
       "98  33                  23                12                3        4   \n",
       "99  34                  19                12                3        4   \n",
       "\n",
       "    Transportation expense  Distance from Residence to Work  Service time  \\\n",
       "0                      289                               36            13   \n",
       "1                      118                               13            18   \n",
       "2                      179                               51            18   \n",
       "3                      279                                5            14   \n",
       "4                      289                               36            13   \n",
       "..                     ...                              ...           ...   \n",
       "95                     225                               26             9   \n",
       "96                     289                               36            13   \n",
       "97                     291                               31            12   \n",
       "98                     248                               25            14   \n",
       "99                     118                               10            10   \n",
       "\n",
       "    Age  Work load Average/day  ...  Disciplinary failure  Education  Son  \\\n",
       "0    33                239.554  ...                     0          1    2   \n",
       "1    50                239.554  ...                     1          1    1   \n",
       "2    38                239.554  ...                     0          1    0   \n",
       "3    39                239.554  ...                     0          1    2   \n",
       "4    33                239.554  ...                     0          1    2   \n",
       "..  ...                    ...  ...                   ...        ...  ...   \n",
       "95   28                306.345  ...                     0          1    1   \n",
       "96   33                306.345  ...                     0          1    2   \n",
       "97   40                306.345  ...                     0          1    1   \n",
       "98   47                261.306  ...                     0          1    2   \n",
       "99   37                261.306  ...                     0          1    0   \n",
       "\n",
       "    Social drinker  Social smoker  Pet  Weight  Height  Body mass index  \\\n",
       "0                1              0    1      90     172               30   \n",
       "1                1              0    0      98     178               31   \n",
       "2                1              0    0      89     170               31   \n",
       "3                1              1    0      68     168               24   \n",
       "4                1              0    1      90     172               30   \n",
       "..             ...            ...  ...     ...     ...              ...   \n",
       "95               0              0    2      69     169               24   \n",
       "96               1              0    1      90     172               30   \n",
       "97               1              0    1      73     171               25   \n",
       "98               0              0    1      86     165               32   \n",
       "99               0              0    0      83     172               28   \n",
       "\n",
       "    Absenteeism time in hours  \n",
       "0                           4  \n",
       "1                           0  \n",
       "2                           2  \n",
       "3                           4  \n",
       "4                           2  \n",
       "..                        ...  \n",
       "95                          3  \n",
       "96                         24  \n",
       "97                          3  \n",
       "98                          1  \n",
       "99                         64  \n",
       "\n",
       "[100 rows x 21 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading in the data\n",
    "absentee_data_pd = pd.read_csv('Absenteeism_at_work.csv', sep = ';')\n",
    "\n",
    "# Reformatting variable names to replace spaces with _\n",
    "#absentee_data_pd.columns = absentee_data_pd.columns.str.replace(\" \", \"_\")\n",
    "\n",
    "# Using the head() method to make sure everything looks as expected\n",
    "absentee_data_pd.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "2ba3feef-01bd-40d5-bbf6-6323c0e339e7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 740 entries, 0 to 739\n",
      "Data columns (total 21 columns):\n",
      " #   Column                           Non-Null Count  Dtype  \n",
      "---  ------                           --------------  -----  \n",
      " 0   ID                               740 non-null    int64  \n",
      " 1   Reason for absence               740 non-null    int64  \n",
      " 2   Month of absence                 740 non-null    int64  \n",
      " 3   Day of the week                  740 non-null    int64  \n",
      " 4   Seasons                          740 non-null    int64  \n",
      " 5   Transportation expense           740 non-null    int64  \n",
      " 6   Distance from Residence to Work  740 non-null    int64  \n",
      " 7   Service time                     740 non-null    int64  \n",
      " 8   Age                              740 non-null    int64  \n",
      " 9   Work load Average/day            740 non-null    float64\n",
      " 10  Hit target                       740 non-null    int64  \n",
      " 11  Disciplinary failure             740 non-null    int64  \n",
      " 12  Education                        740 non-null    int64  \n",
      " 13  Son                              740 non-null    int64  \n",
      " 14  Social drinker                   740 non-null    int64  \n",
      " 15  Social smoker                    740 non-null    int64  \n",
      " 16  Pet                              740 non-null    int64  \n",
      " 17  Weight                           740 non-null    int64  \n",
      " 18  Height                           740 non-null    int64  \n",
      " 19  Body mass index                  740 non-null    int64  \n",
      " 20  Absenteeism time in hours        740 non-null    int64  \n",
      "dtypes: float64(1), int64(20)\n",
      "memory usage: 121.5 KB\n"
     ]
    }
   ],
   "source": [
    "absentee_data_pd.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44afa3a9-f777-4b25-a9f0-19507efa822d",
   "metadata": {},
   "source": [
    "### Summary Statistics About Our Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d9e4d806-e9ce-462b-b705-94eb127db6fb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Reason_for_absence</th>\n",
       "      <th>Month_of_absence</th>\n",
       "      <th>Day_of_the_week</th>\n",
       "      <th>Seasons</th>\n",
       "      <th>Transportation_expense</th>\n",
       "      <th>Distance_from_Residence_to_Work</th>\n",
       "      <th>Service_time</th>\n",
       "      <th>Age</th>\n",
       "      <th>Work_load_Average/day_</th>\n",
       "      <th>...</th>\n",
       "      <th>Disciplinary_failure</th>\n",
       "      <th>Education</th>\n",
       "      <th>Son</th>\n",
       "      <th>Social_drinker</th>\n",
       "      <th>Social_smoker</th>\n",
       "      <th>Pet</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Height</th>\n",
       "      <th>Body_mass_index</th>\n",
       "      <th>Absenteeism_time_in_hours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>740.000000</td>\n",
       "      <td>740.000000</td>\n",
       "      <td>740.000000</td>\n",
       "      <td>740.000000</td>\n",
       "      <td>740.000000</td>\n",
       "      <td>740.000000</td>\n",
       "      <td>740.000000</td>\n",
       "      <td>740.000000</td>\n",
       "      <td>740.000000</td>\n",
       "      <td>740.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>740.000000</td>\n",
       "      <td>740.000000</td>\n",
       "      <td>740.000000</td>\n",
       "      <td>740.000000</td>\n",
       "      <td>740.000000</td>\n",
       "      <td>740.000000</td>\n",
       "      <td>740.000000</td>\n",
       "      <td>740.000000</td>\n",
       "      <td>740.000000</td>\n",
       "      <td>740.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>18.017568</td>\n",
       "      <td>19.216216</td>\n",
       "      <td>6.324324</td>\n",
       "      <td>3.914865</td>\n",
       "      <td>2.544595</td>\n",
       "      <td>221.329730</td>\n",
       "      <td>29.631081</td>\n",
       "      <td>12.554054</td>\n",
       "      <td>36.450000</td>\n",
       "      <td>271.490235</td>\n",
       "      <td>...</td>\n",
       "      <td>0.054054</td>\n",
       "      <td>1.291892</td>\n",
       "      <td>1.018919</td>\n",
       "      <td>0.567568</td>\n",
       "      <td>0.072973</td>\n",
       "      <td>0.745946</td>\n",
       "      <td>79.035135</td>\n",
       "      <td>172.114865</td>\n",
       "      <td>26.677027</td>\n",
       "      <td>6.924324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>11.021247</td>\n",
       "      <td>8.433406</td>\n",
       "      <td>3.436287</td>\n",
       "      <td>1.421675</td>\n",
       "      <td>1.111831</td>\n",
       "      <td>66.952223</td>\n",
       "      <td>14.836788</td>\n",
       "      <td>4.384873</td>\n",
       "      <td>6.478772</td>\n",
       "      <td>39.058116</td>\n",
       "      <td>...</td>\n",
       "      <td>0.226277</td>\n",
       "      <td>0.673238</td>\n",
       "      <td>1.098489</td>\n",
       "      <td>0.495749</td>\n",
       "      <td>0.260268</td>\n",
       "      <td>1.318258</td>\n",
       "      <td>12.883211</td>\n",
       "      <td>6.034995</td>\n",
       "      <td>4.285452</td>\n",
       "      <td>13.330998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>118.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>205.917000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>163.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>179.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>244.387000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>169.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>225.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>264.249000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>83.000000</td>\n",
       "      <td>170.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>28.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>260.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>294.217000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>89.000000</td>\n",
       "      <td>172.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>36.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>388.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>378.884000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>108.000000</td>\n",
       "      <td>196.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>120.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               ID  Reason_for_absence  Month_of_absence  Day_of_the_week  \\\n",
       "count  740.000000          740.000000        740.000000       740.000000   \n",
       "mean    18.017568           19.216216          6.324324         3.914865   \n",
       "std     11.021247            8.433406          3.436287         1.421675   \n",
       "min      1.000000            0.000000          0.000000         2.000000   \n",
       "25%      9.000000           13.000000          3.000000         3.000000   \n",
       "50%     18.000000           23.000000          6.000000         4.000000   \n",
       "75%     28.000000           26.000000          9.000000         5.000000   \n",
       "max     36.000000           28.000000         12.000000         6.000000   \n",
       "\n",
       "          Seasons  Transportation_expense  Distance_from_Residence_to_Work  \\\n",
       "count  740.000000              740.000000                       740.000000   \n",
       "mean     2.544595              221.329730                        29.631081   \n",
       "std      1.111831               66.952223                        14.836788   \n",
       "min      1.000000              118.000000                         5.000000   \n",
       "25%      2.000000              179.000000                        16.000000   \n",
       "50%      3.000000              225.000000                        26.000000   \n",
       "75%      4.000000              260.000000                        50.000000   \n",
       "max      4.000000              388.000000                        52.000000   \n",
       "\n",
       "       Service_time         Age  Work_load_Average/day_  ...  \\\n",
       "count    740.000000  740.000000              740.000000  ...   \n",
       "mean      12.554054   36.450000              271.490235  ...   \n",
       "std        4.384873    6.478772               39.058116  ...   \n",
       "min        1.000000   27.000000              205.917000  ...   \n",
       "25%        9.000000   31.000000              244.387000  ...   \n",
       "50%       13.000000   37.000000              264.249000  ...   \n",
       "75%       16.000000   40.000000              294.217000  ...   \n",
       "max       29.000000   58.000000              378.884000  ...   \n",
       "\n",
       "       Disciplinary_failure   Education         Son  Social_drinker  \\\n",
       "count            740.000000  740.000000  740.000000      740.000000   \n",
       "mean               0.054054    1.291892    1.018919        0.567568   \n",
       "std                0.226277    0.673238    1.098489        0.495749   \n",
       "min                0.000000    1.000000    0.000000        0.000000   \n",
       "25%                0.000000    1.000000    0.000000        0.000000   \n",
       "50%                0.000000    1.000000    1.000000        1.000000   \n",
       "75%                0.000000    1.000000    2.000000        1.000000   \n",
       "max                1.000000    4.000000    4.000000        1.000000   \n",
       "\n",
       "       Social_smoker         Pet      Weight      Height  Body_mass_index  \\\n",
       "count     740.000000  740.000000  740.000000  740.000000       740.000000   \n",
       "mean        0.072973    0.745946   79.035135  172.114865        26.677027   \n",
       "std         0.260268    1.318258   12.883211    6.034995         4.285452   \n",
       "min         0.000000    0.000000   56.000000  163.000000        19.000000   \n",
       "25%         0.000000    0.000000   69.000000  169.000000        24.000000   \n",
       "50%         0.000000    0.000000   83.000000  170.000000        25.000000   \n",
       "75%         0.000000    1.000000   89.000000  172.000000        31.000000   \n",
       "max         1.000000    8.000000  108.000000  196.000000        38.000000   \n",
       "\n",
       "       Absenteeism_time_in_hours  \n",
       "count                 740.000000  \n",
       "mean                    6.924324  \n",
       "std                    13.330998  \n",
       "min                     0.000000  \n",
       "25%                     2.000000  \n",
       "50%                     3.000000  \n",
       "75%                     8.000000  \n",
       "max                   120.000000  \n",
       "\n",
       "[8 rows x 21 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "absentee_data_pd.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7e74e103-f5bd-44fd-a7bc-133d49e7457f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "absentee_data_pd.ID.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7d0153e6-c7b2-4294-979f-24ca27d9dd1a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23    149\n",
       "28    112\n",
       "27     69\n",
       "13     55\n",
       "0      43\n",
       "19     40\n",
       "22     38\n",
       "26     33\n",
       "25     31\n",
       "11     26\n",
       "10     25\n",
       "18     21\n",
       "14     19\n",
       "1      16\n",
       "7      15\n",
       "6       8\n",
       "12      8\n",
       "21      6\n",
       "8       6\n",
       "9       4\n",
       "5       3\n",
       "16      3\n",
       "24      3\n",
       "15      2\n",
       "4       2\n",
       "3       1\n",
       "2       1\n",
       "17      1\n",
       "Name: Reason_for_absence, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "absentee_data_pd.Reason_for_absence.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cb2db3c8-f522-4329-b603-58efd6966dc8",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3     113\n",
       "28     76\n",
       "34     55\n",
       "22     46\n",
       "20     42\n",
       "11     40\n",
       "15     37\n",
       "36     34\n",
       "24     30\n",
       "14     29\n",
       "33     24\n",
       "10     24\n",
       "1      23\n",
       "17     20\n",
       "5      19\n",
       "18     16\n",
       "13     15\n",
       "25     10\n",
       "9       8\n",
       "6       8\n",
       "23      8\n",
       "27      7\n",
       "12      7\n",
       "30      7\n",
       "2       6\n",
       "7       6\n",
       "26      5\n",
       "32      5\n",
       "29      5\n",
       "19      3\n",
       "21      3\n",
       "31      3\n",
       "8       2\n",
       "16      2\n",
       "4       1\n",
       "35      1\n",
       "Name: ID, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "absentee_data_pd.ID.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b119d65-61ba-4a89-a295-a10cbf0cbaa7",
   "metadata": {},
   "source": [
    "We can now convert `absentee_data_pd` to a Spark SQL dataframe. We will save this as `absentee_spark_df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30065505-14a9-46ea-9afa-6bbaabca3626",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/spark/python/pyspark/sql/pandas/conversion.py:474: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for column, series in pdf.iteritems():\n",
      "/usr/local/spark/python/pyspark/sql/pandas/conversion.py:486: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for column, series in pdf.iteritems():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------------+----------------+---------------+-------+----------------------+-------------------------------+------------+---+---------------------+----------+--------------------+---------+---+--------------+-------------+---+------+------+---------------+-------------------------+\n",
      "| ID|Reason for absence|Month of absence|Day of the week|Seasons|Transportation expense|Distance from Residence to Work|Service time|Age|Work load Average/day|Hit target|Disciplinary failure|Education|Son|Social drinker|Social smoker|Pet|Weight|Height|Body mass index|Absenteeism time in hours|\n",
      "+---+------------------+----------------+---------------+-------+----------------------+-------------------------------+------------+---+---------------------+----------+--------------------+---------+---+--------------+-------------+---+------+------+---------------+-------------------------+\n",
      "| 11|                26|               7|              3|      1|                   289|                             36|          13| 33|              239.554|        97|                   0|        1|  2|             1|            0|  1|    90|   172|             30|                        4|\n",
      "| 36|                 0|               7|              3|      1|                   118|                             13|          18| 50|              239.554|        97|                   1|        1|  1|             1|            0|  0|    98|   178|             31|                        0|\n",
      "|  3|                23|               7|              4|      1|                   179|                             51|          18| 38|              239.554|        97|                   0|        1|  0|             1|            0|  0|    89|   170|             31|                        2|\n",
      "|  7|                 7|               7|              5|      1|                   279|                              5|          14| 39|              239.554|        97|                   0|        1|  2|             1|            1|  0|    68|   168|             24|                        4|\n",
      "| 11|                23|               7|              5|      1|                   289|                             36|          13| 33|              239.554|        97|                   0|        1|  2|             1|            0|  1|    90|   172|             30|                        2|\n",
      "+---+------------------+----------------+---------------+-------+----------------------+-------------------------------+------------+---+---------------------+----------+--------------------+---------+---+--------------+-------------+---+------+------+---------------+-------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "absentee_spark_df = spark.createDataFrame(absentee_data_pd)\n",
    "absentee_spark_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59201bb4-8d1b-4de9-8034-e03bc7c8d96b",
   "metadata": {},
   "source": [
    "#### Formatting Column Names  \n",
    "\n",
    "The original dataset contains variable names with spaces. To make things easier let's replace the spaces in any of the column names with `_` to prevent issues that might arise from the spaces being present in our names. First, we will simply create a list where we have replaced any space in a column name with an underscore. We will then use this list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a9d4bf-3110-41d5-a765-bfc377e9fb33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9569651-6e13-46d5-ab3d-55859955e3a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ID', 'Reason_for_absence', 'Month_of_absence', 'Day_of_the_week', 'Seasons', 'Transportation_expense', 'Distance_from_Residence_to_Work', 'Service_time', 'Age', 'Work_load_Average/day', 'Hit_target', 'Disciplinary_failure', 'Education', 'Son', 'Social_drinker', 'Social_smoker', 'Pet', 'Weight', 'Height', 'Body_mass_index', 'Absenteeism_time_in_hours']\n"
     ]
    }
   ],
   "source": [
    "new_columns = list(map(lambda item : item.replace(\" \",\"_\"),absentee_spark_df.columns))\n",
    "print(new_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "04794b15-87f7-4ed9-b9c5-9f870976e89d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ID: long (nullable = true)\n",
      " |-- Reason_for_absence: long (nullable = true)\n",
      " |-- Month_of_absence: long (nullable = true)\n",
      " |-- Day_of_the_week: long (nullable = true)\n",
      " |-- Seasons: long (nullable = true)\n",
      " |-- Transportation_expense: long (nullable = true)\n",
      " |-- Distance_from_Residence_to_Work: long (nullable = true)\n",
      " |-- Service_time: long (nullable = true)\n",
      " |-- Age: long (nullable = true)\n",
      " |-- Workload_per_day: double (nullable = true)\n",
      " |-- Hit_target: long (nullable = true)\n",
      " |-- Disciplinary_failure: long (nullable = true)\n",
      " |-- Education: long (nullable = true)\n",
      " |-- Son: long (nullable = true)\n",
      " |-- Social_drinker: long (nullable = true)\n",
      " |-- Social_smoker: long (nullable = true)\n",
      " |-- Pet: long (nullable = true)\n",
      " |-- Weight: long (nullable = true)\n",
      " |-- Height: long (nullable = true)\n",
      " |-- Body_mass_index: long (nullable = true)\n",
      " |-- Absenteeism_time_in_hours: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from functools import reduce\n",
    "\n",
    "absentee_data = reduce(lambda data, column_name: data.withColumnRenamed(absentee_spark_df.columns[column_name], new_columns[column_name]), range(len(absentee_spark_df.columns)), absentee_spark_df)\n",
    "absentee_data = absentee_data.withColumnRenamed(\"Work_load_Average/day\", \"Workload_per_day\")\n",
    "absentee_data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6098e4d1-5ca9-42de-8b57-aed7f2670106",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>summary</th>\n",
       "      <td>count</td>\n",
       "      <td>mean</td>\n",
       "      <td>stddev</td>\n",
       "      <td>min</td>\n",
       "      <td>max</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <td>740</td>\n",
       "      <td>18.017567567567568</td>\n",
       "      <td>11.021247263063655</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Reason_for_absence</th>\n",
       "      <td>740</td>\n",
       "      <td>19.216216216216218</td>\n",
       "      <td>8.433405882799654</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Month_of_absence</th>\n",
       "      <td>740</td>\n",
       "      <td>6.324324324324325</td>\n",
       "      <td>3.4362869319125893</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Day_of_the_week</th>\n",
       "      <td>740</td>\n",
       "      <td>3.9148648648648647</td>\n",
       "      <td>1.4216747097562803</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Seasons</th>\n",
       "      <td>740</td>\n",
       "      <td>2.5445945945945945</td>\n",
       "      <td>1.111831060157382</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Transportation_expense</th>\n",
       "      <td>740</td>\n",
       "      <td>221.32972972972973</td>\n",
       "      <td>66.95222324531973</td>\n",
       "      <td>118</td>\n",
       "      <td>388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Distance_from_Residence_to_Work</th>\n",
       "      <td>740</td>\n",
       "      <td>29.63108108108108</td>\n",
       "      <td>14.836788436739145</td>\n",
       "      <td>5</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Service_time</th>\n",
       "      <td>740</td>\n",
       "      <td>12.554054054054054</td>\n",
       "      <td>4.384873407621149</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>740</td>\n",
       "      <td>36.45</td>\n",
       "      <td>6.47877245761187</td>\n",
       "      <td>27</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Workload_per_day</th>\n",
       "      <td>740</td>\n",
       "      <td>271.4902351351353</td>\n",
       "      <td>39.05811618814401</td>\n",
       "      <td>205.917</td>\n",
       "      <td>378.884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hit_target</th>\n",
       "      <td>740</td>\n",
       "      <td>94.58783783783784</td>\n",
       "      <td>3.7793131344179947</td>\n",
       "      <td>81</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Disciplinary_failure</th>\n",
       "      <td>740</td>\n",
       "      <td>0.05405405405405406</td>\n",
       "      <td>0.22627727323215055</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Education</th>\n",
       "      <td>740</td>\n",
       "      <td>1.2918918918918918</td>\n",
       "      <td>0.6732380415251594</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Son</th>\n",
       "      <td>740</td>\n",
       "      <td>1.018918918918919</td>\n",
       "      <td>1.0984890195302819</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Social_drinker</th>\n",
       "      <td>740</td>\n",
       "      <td>0.5675675675675675</td>\n",
       "      <td>0.495748667200035</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Social_smoker</th>\n",
       "      <td>740</td>\n",
       "      <td>0.07297297297297298</td>\n",
       "      <td>0.2602680502800184</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pet</th>\n",
       "      <td>740</td>\n",
       "      <td>0.745945945945946</td>\n",
       "      <td>1.3182582913258338</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Weight</th>\n",
       "      <td>740</td>\n",
       "      <td>79.03513513513514</td>\n",
       "      <td>12.883210507177221</td>\n",
       "      <td>56</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Height</th>\n",
       "      <td>740</td>\n",
       "      <td>172.11486486486487</td>\n",
       "      <td>6.03499453026766</td>\n",
       "      <td>163</td>\n",
       "      <td>196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Body_mass_index</th>\n",
       "      <td>740</td>\n",
       "      <td>26.677027027027027</td>\n",
       "      <td>4.285452223167275</td>\n",
       "      <td>19</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Absenteeism_time_in_hours</th>\n",
       "      <td>740</td>\n",
       "      <td>6.924324324324324</td>\n",
       "      <td>13.330998100978201</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     0                    1  \\\n",
       "summary                          count                 mean   \n",
       "ID                                 740   18.017567567567568   \n",
       "Reason_for_absence                 740   19.216216216216218   \n",
       "Month_of_absence                   740    6.324324324324325   \n",
       "Day_of_the_week                    740   3.9148648648648647   \n",
       "Seasons                            740   2.5445945945945945   \n",
       "Transportation_expense             740   221.32972972972973   \n",
       "Distance_from_Residence_to_Work    740    29.63108108108108   \n",
       "Service_time                       740   12.554054054054054   \n",
       "Age                                740                36.45   \n",
       "Workload_per_day                   740    271.4902351351353   \n",
       "Hit_target                         740    94.58783783783784   \n",
       "Disciplinary_failure               740  0.05405405405405406   \n",
       "Education                          740   1.2918918918918918   \n",
       "Son                                740    1.018918918918919   \n",
       "Social_drinker                     740   0.5675675675675675   \n",
       "Social_smoker                      740  0.07297297297297298   \n",
       "Pet                                740    0.745945945945946   \n",
       "Weight                             740    79.03513513513514   \n",
       "Height                             740   172.11486486486487   \n",
       "Body_mass_index                    740   26.677027027027027   \n",
       "Absenteeism_time_in_hours          740    6.924324324324324   \n",
       "\n",
       "                                                   2        3        4  \n",
       "summary                                       stddev      min      max  \n",
       "ID                                11.021247263063655        1       36  \n",
       "Reason_for_absence                 8.433405882799654        0       28  \n",
       "Month_of_absence                  3.4362869319125893        0       12  \n",
       "Day_of_the_week                   1.4216747097562803        2        6  \n",
       "Seasons                            1.111831060157382        1        4  \n",
       "Transportation_expense             66.95222324531973      118      388  \n",
       "Distance_from_Residence_to_Work   14.836788436739145        5       52  \n",
       "Service_time                       4.384873407621149        1       29  \n",
       "Age                                 6.47877245761187       27       58  \n",
       "Workload_per_day                   39.05811618814401  205.917  378.884  \n",
       "Hit_target                        3.7793131344179947       81      100  \n",
       "Disciplinary_failure             0.22627727323215055        0        1  \n",
       "Education                         0.6732380415251594        1        4  \n",
       "Son                               1.0984890195302819        0        4  \n",
       "Social_drinker                     0.495748667200035        0        1  \n",
       "Social_smoker                     0.2602680502800184        0        1  \n",
       "Pet                               1.3182582913258338        0        8  \n",
       "Weight                            12.883210507177221       56      108  \n",
       "Height                              6.03499453026766      163      196  \n",
       "Body_mass_index                    4.285452223167275       19       38  \n",
       "Absenteeism_time_in_hours         13.330998100978201        0      120  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "absentee_data.describe().toPandas().transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdbff617-1068-4aba-8662-9ed44abfb90e",
   "metadata": {},
   "source": [
    "# Splitting the Data, Metrics, and Models  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cdd7285-0763-426e-ac14-708d4fe73cf0",
   "metadata": {},
   "source": [
    "## Model Metrics  \n",
    "\n",
    "Model metrics are used to determine the quality of the predictions produced by our models. There are many different model metrics that are available to determine how close our predictions are to the actual values of the response variable, but the specific metric selected depends on the type of data you are attempting to make predictions for with your model.  \n",
    "\n",
    "In this example we are building models that will predict a continuous numeric variable (`Absenteeism time in hours`). Regression models are used when the goal is to predict a continuous response, and all of the models presented in this analysis will be regression models. The most common way to fit a regression model is based on minimizing the sum of squared errors, which can be done with or without including a penalty.  To evaluate the performance of our models we will utilize two of the most commonly used model metrics for regression problems, root mean squared error (RMSE) and mean absolute error (MAE).\n",
    "\n",
    "### RMSE - Root Mean Squared Error   \n",
    "\n",
    "RMSE is one of the most popular model metrics used to evaluate regression model performance. When comparing models built on the same target variable and the same dataset, the more accurate the model, the lower the RMSE value produced. \n",
    "\n",
    "RMSE is the square root of the mean squared error between the predicted values produced by our model and the actual values of the target variable. This value is calculated by subtracting the predicted value from the actual value of our response variable and then squaring this value. This is then summed up over all of the observations in our dataset, divided by the number of observations, and then taking the square root of that resulting value.  \n",
    "\n",
    "One big advantage of using RMSE over other possible metrics is that it produces values that are in the same units as our response/target variable, and is therefore fairly easy to understand.   \n",
    "\n",
    "Potential disadvantages of using RMSE as a model metric are the fact that it can be more sensitive to outliers in the data than other methods and that it will penalize large errors in prediction more than other methods. This is due to the fact that in the RMSE calculation we are squaring the error, meaning that outliers will result in larger prediction errors and will be penalized more heavily than in other methods such as mean absolute error. It is important to note that this sensitivity to outliers can be a benefit depending on the context of the problem at hand. In many cases we may want to minimize occasional large mistakes in our predictions and would want to use a model metric that would penalize outliers more heavily.\n",
    "\n",
    "\n",
    "### MAE - Mean Absolute Error  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e813f4-88d5-4bcc-b034-18f3c581f153",
   "metadata": {},
   "source": [
    "## Splitting the Data into Training and Test Sets   \n",
    "\n",
    "The goal of creating our supervised models is to be able to successfully predict the number of absentee hours on new data, that is, on data that was not used to train our model. We want our model to be able to generalize to new data. In order to build a model that will be able to generalize we must be careful to not overfit our model to the data used to build it. If we build a model that is perfect at predicting our response variable based on data that was used to build the model, but largely fails to predict our response variable when new data is used to generate predictions, it is clear to see that our model will not be very useful. \n",
    "\n",
    "One common way to combat the problem of overfitting our model is to split the data into a training set and a test set. The exact split to use for a training vs test set can vary, but it is common to see an 80/20 or 70/30 training vs test set split. Once the data has been split into training and test sets we can use the training set to fit our model. Often we will want to use model metrics to evaluate the predictions produced by our model based on the observations contained in our training set that were used to fit that model.  \n",
    "\n",
    "Now, let's split our data into training and test sets.  We can do this by using the `.randomSplit()` method on our spark SQL data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7edbb19a-b50f-4199-a1ba-aa59329101bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "581 159\n"
     ]
    }
   ],
   "source": [
    "train, test = absentee_data.randomSplit([0.8,0.2], seed = 1234)\n",
    "print(train.count(), test.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38435012-34cf-4587-a581-3af73053367c",
   "metadata": {},
   "source": [
    "## Models  \n",
    "\n",
    "Statistical learning is used for inference, prediction, classification, and pattern finding based on your data. A statistical learning model is a mathematical representation of some phenomenon on which data has been observed and collected. We will built 5 different classes of supervised statistical learning models to predict the value of our response variable, the number of absentee hours. In this section we will briefly discuss the concepts and ideas involved in each of our five classes of models. In the next section, [Model Fitting Using Spark MLlib](#Model-Fitting-Using-Spark-MLlib), we will build and fit our models on the training data set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ad05bb-3f75-4db6-8ff2-04cb03ab4bb8",
   "metadata": {},
   "source": [
    "### Model 1  - Multiple Linear Regression  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd6fbba-6430-4ef2-a878-40e25696286e",
   "metadata": {},
   "source": [
    "### Model 2  - Regression Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c171b7ca-10ce-47aa-afaa-465f09c18c34",
   "metadata": {},
   "source": [
    "### Model 3 - Random Forest "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16adb44-2378-483c-a036-8aac6ae8eb7c",
   "metadata": {},
   "source": [
    "### Model 4  - Gradient Boosted Regression Tree   \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fec3840-7113-478b-83a8-5fb121e1efbb",
   "metadata": {},
   "source": [
    "### Model 5 - LASSO Regression    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4007df2b-c9ef-4fb1-ac1a-08cabfff0ab7",
   "metadata": {},
   "source": [
    "# Model Fitting Using Spark MLlib and `CrossValidation()`\n",
    "\n",
    "We will be using cross-validation for model selection and hyperparameter tuning.  \n",
    "\n",
    "First, let's import the required libraries and functions that we will need to build our models. These will be used in all models, additional libraries or functions that are needed for specific models will be imported as needed within each model section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e3784ec0-5f21-46a0-b430-dd2952f25fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import SQLTransformer, VectorAssembler, StandardScaler, OneHotEncoder\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml.evaluation import RegressionEvaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68891d8a-d119-4685-83ad-69fcf0ebd054",
   "metadata": {},
   "source": [
    "### Transformations and Preprocessing Using `MLlib` Functions  \n",
    "\n",
    "The transformations in this section will be used in one or more of our model pipelines."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec8b746-2011-44bd-b144-423bc2462e6b",
   "metadata": {},
   "source": [
    "#### `sql_trans_label` Selecting Variables for Modeling and Creating Label Column  \n",
    "\n",
    "The `sql_trans_label` transformation uses `SQLTransformer()` to create the `label` column in our data set. We will also select only the variables that we want to include when building our models. We will drop the variables below from our dataset:\n",
    "\n",
    "-  `ID` - This is a personal identifier of each employee. As we are concerned with predicting the number of absentee hours for a given instance, `ID` will not be needed to build our model.  \n",
    "-  `Body_mass_index` - We will drop this variable as it is a function of height and weight, and is highly correlated with both.  \n",
    "-  `Month_of_absence` - We will drop this variable because it contains similar information to the `Seasons` variable, with many additional levels as compared to the `Seasons` variable.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f95241b-336e-4be2-8634-8e891b37f817",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_trans_label = SQLTransformer(\n",
    "    statement = \"\"\"\n",
    "                SELECT Reason_for_absence, Day_of_the_week, Seasons, Transportation_expense, Distance_from_Residence_to_Work, Service_time, \\\n",
    "                Age, Workload_per_day, Hit_target, Disciplinary_failure, Education, Son, Social_drinker, Social_smoker, Pet, Weight, \\\n",
    "                Height, Absenteeism_time_in_hours AS label FROM __THIS__\n",
    "                \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2907d8c-acf3-455c-9271-b6260788c17f",
   "metadata": {},
   "source": [
    "Let's just do a quick check that this works as expected. We will use `.toPandas()` to display the data frame as a pandas dataframe. This will not change the `absentee_data` dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7046c3af-30f7-4052-b366-4429d05f36e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Reason_for_absence',\n",
       " 'Day_of_the_week',\n",
       " 'Seasons',\n",
       " 'Transportation_expense',\n",
       " 'Distance_from_Residence_to_Work',\n",
       " 'Service_time',\n",
       " 'Age',\n",
       " 'Workload_per_day',\n",
       " 'Hit_target',\n",
       " 'Disciplinary_failure',\n",
       " 'Education',\n",
       " 'Son',\n",
       " 'Social_drinker',\n",
       " 'Social_smoker',\n",
       " 'Pet',\n",
       " 'Weight',\n",
       " 'Height',\n",
       " 'label']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql_trans_label.transform(absentee_data).columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd3c46e6-3345-4191-94f0-a8d9fd52ab2d",
   "metadata": {},
   "source": [
    "#### `scale_trans` Standardizing Numeric Variables  \n",
    "\n",
    "It is important that we standardize our numeric variables before building our models. Some of the predictor variables that we are using have different units and very different scales, such as `Transporation_expense` with a maximum value of `388` compared to `Son` (number of children) with a maximum value of `4`.  The variables the we will standardize are:  \n",
    "\n",
    "-  `Transportation_expense` - The standardized version will be called `Transportaion_expense_scaled`  \n",
    "-  `Distance_from_Residence_to_Work` The standardized version will be called `Distance_from_Residence_to_Work_scaled`  \n",
    "-  `Service_time` The standardized version will be called `Service_time_scaled`  \n",
    "-  `Age` The standardized version will be called `Age_scaled`  \n",
    "-  `Workload_per_day` The standardized version will be called `Workload_per_day_scaled`\n",
    "-  `Hit_target` The standardized version will be called `Hit_target_scaled`  \n",
    "-  `Son` The standardized version will be called `Son_scaled`  \n",
    "-  `Pet` The standardized version will be called `Pet_scaled`  \n",
    "-  `Weight` The standardized version will be called `Weight_scaled`  \n",
    "-  `Height` The standardized version will be called `Height_scaled`  \n",
    "\n",
    "*Note that we will add these to our data frame without removing the original variables*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "500c8c12-6b8c-4ac5-85fa-35ffabb0cbc1",
   "metadata": {},
   "source": [
    "https://www.analyticsvidhya.com/blog/2022/06/building-a-machine-learning-pipeline-using-pyspark/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dcad7fba-9b82-4834-89b0-59589b2e53ab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ID',\n",
       " 'Reason_for_absence',\n",
       " 'Month_of_absence',\n",
       " 'Day_of_the_week',\n",
       " 'Seasons',\n",
       " 'Transportation_expense',\n",
       " 'Distance_from_Residence_to_Work',\n",
       " 'Service_time',\n",
       " 'Age',\n",
       " 'Workload_per_day',\n",
       " 'Hit_target',\n",
       " 'Disciplinary_failure',\n",
       " 'Education',\n",
       " 'Son',\n",
       " 'Social_drinker',\n",
       " 'Social_smoker',\n",
       " 'Pet',\n",
       " 'Weight',\n",
       " 'Height',\n",
       " 'Body_mass_index',\n",
       " 'Absenteeism_time_in_hours',\n",
       " 'Transportation_expense_vec',\n",
       " 'Distance_from_Residence_to_Work_vec',\n",
       " 'Service_time_vec',\n",
       " 'Age_vec',\n",
       " 'Workload_per_day_vec',\n",
       " 'Hit_target_vec',\n",
       " 'Son_vec',\n",
       " 'Pet_vec',\n",
       " 'Weight_vec',\n",
       " 'Height_vec',\n",
       " 'Transportation_expense_scaled',\n",
       " 'Distance_from_Residence_to_Work_scaled',\n",
       " 'Service_time_scaled',\n",
       " 'Age_scaled',\n",
       " 'Workload_per_day_scaled',\n",
       " 'Hit_target_scaled',\n",
       " 'Son_scaled',\n",
       " 'Pet_scaled',\n",
       " 'Weight_scaled',\n",
       " 'Height_scaled']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a list of numeric column names that we want to scale\n",
    "numeric_cols = ['Transportation_expense', 'Distance_from_Residence_to_Work', 'Service_time', 'Age', 'Workload_per_day', \\\n",
    "                                    'Hit_target', 'Son', 'Pet', 'Weight', 'Height']\n",
    "assembler = [VectorAssembler(inputCols=[col], outputCol=col+'_vec') for col in numeric_cols]\n",
    "scale = [StandardScaler(inputCol=col+'_vec', outputCol=col+'_scaled', withMean=True, withStd=True) for col in numeric_cols]\n",
    "scale_pipe = Pipeline(stages = assembler + scale)\n",
    "scale_trans = scale_pipe.fit(absentee_data)\n",
    "scale_trans.transform(absentee_data).columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "186aecd1-66e4-44f8-aee9-c7b4112c9fcd",
   "metadata": {},
   "source": [
    "#### `encoder_trans` Creating Dummy Variables for Categorical Variables in the Dataset  \n",
    "\n",
    "Before we build our models we want to create dummy variables for the non-binary categorical variables in our dataset. We will use `OneHotEncoder()` from `MLlib` to create these dummy variables for us. We will create dummy variables for:  \n",
    "-  `Reason_for_absence` - The encoded reason for absence variable will be called `Reason_onehot`    \n",
    "-  `Day_of_the_week` - The encoded day of the week variable will be called `Day_onehot`  \n",
    "-  `Seasons` - The encoded seasons variable will be called `Season_onehot`  \n",
    "\n",
    "*Note that we will add these to our data frame without removing the original variables*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "de1a9c92-a40a-4a3b-9edd-f90d52ec77c0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------------+----------------+---------------+-------+----------------------+-------------------------------+------------+---+----------------+----------+--------------------+---------+---+--------------+-------------+---+------+------+---------------+-------------------------+---------------+-------------+-------------+\n",
      "| ID|Reason_for_absence|Month_of_absence|Day_of_the_week|Seasons|Transportation_expense|Distance_from_Residence_to_Work|Service_time|Age|Workload_per_day|Hit_target|Disciplinary_failure|Education|Son|Social_drinker|Social_smoker|Pet|Weight|Height|Body_mass_index|Absenteeism_time_in_hours|  Reason_onehot|   Day_onehot|Season_onehot|\n",
      "+---+------------------+----------------+---------------+-------+----------------------+-------------------------------+------------+---+----------------+----------+--------------------+---------+---+--------------+-------------+---+------+------+---------------+-------------------------+---------------+-------------+-------------+\n",
      "| 11|                26|               7|              3|      1|                   289|                             36|          13| 33|         239.554|        97|                   0|        1|  2|             1|            0|  1|    90|   172|             30|                        4|(28,[26],[1.0])|(6,[3],[1.0])|(4,[1],[1.0])|\n",
      "| 36|                 0|               7|              3|      1|                   118|                             13|          18| 50|         239.554|        97|                   1|        1|  1|             1|            0|  0|    98|   178|             31|                        0| (28,[0],[1.0])|(6,[3],[1.0])|(4,[1],[1.0])|\n",
      "|  3|                23|               7|              4|      1|                   179|                             51|          18| 38|         239.554|        97|                   0|        1|  0|             1|            0|  0|    89|   170|             31|                        2|(28,[23],[1.0])|(6,[4],[1.0])|(4,[1],[1.0])|\n",
      "|  7|                 7|               7|              5|      1|                   279|                              5|          14| 39|         239.554|        97|                   0|        1|  2|             1|            1|  0|    68|   168|             24|                        4| (28,[7],[1.0])|(6,[5],[1.0])|(4,[1],[1.0])|\n",
      "| 11|                23|               7|              5|      1|                   289|                             36|          13| 33|         239.554|        97|                   0|        1|  2|             1|            0|  1|    90|   172|             30|                        2|(28,[23],[1.0])|(6,[5],[1.0])|(4,[1],[1.0])|\n",
      "|  3|                23|               7|              6|      1|                   179|                             51|          18| 38|         239.554|        97|                   0|        1|  0|             1|            0|  0|    89|   170|             31|                        2|(28,[23],[1.0])|    (6,[],[])|(4,[1],[1.0])|\n",
      "| 10|                22|               7|              6|      1|                   361|                             52|           3| 28|         239.554|        97|                   0|        1|  1|             1|            0|  4|    80|   172|             27|                        8|(28,[22],[1.0])|    (6,[],[])|(4,[1],[1.0])|\n",
      "| 20|                23|               7|              6|      1|                   260|                             50|          11| 36|         239.554|        97|                   0|        1|  4|             1|            0|  0|    65|   168|             23|                        4|(28,[23],[1.0])|    (6,[],[])|(4,[1],[1.0])|\n",
      "| 14|                19|               7|              2|      1|                   155|                             12|          14| 34|         239.554|        97|                   0|        1|  2|             1|            0|  0|    95|   196|             25|                       40|(28,[19],[1.0])|(6,[2],[1.0])|(4,[1],[1.0])|\n",
      "|  1|                22|               7|              2|      1|                   235|                             11|          14| 37|         239.554|        97|                   0|        3|  1|             0|            0|  1|    88|   172|             29|                        8|(28,[22],[1.0])|(6,[2],[1.0])|(4,[1],[1.0])|\n",
      "| 20|                 1|               7|              2|      1|                   260|                             50|          11| 36|         239.554|        97|                   0|        1|  4|             1|            0|  0|    65|   168|             23|                        8| (28,[1],[1.0])|(6,[2],[1.0])|(4,[1],[1.0])|\n",
      "| 20|                 1|               7|              3|      1|                   260|                             50|          11| 36|         239.554|        97|                   0|        1|  4|             1|            0|  0|    65|   168|             23|                        8| (28,[1],[1.0])|(6,[3],[1.0])|(4,[1],[1.0])|\n",
      "| 20|                11|               7|              4|      1|                   260|                             50|          11| 36|         239.554|        97|                   0|        1|  4|             1|            0|  0|    65|   168|             23|                        8|(28,[11],[1.0])|(6,[4],[1.0])|(4,[1],[1.0])|\n",
      "|  3|                11|               7|              4|      1|                   179|                             51|          18| 38|         239.554|        97|                   0|        1|  0|             1|            0|  0|    89|   170|             31|                        1|(28,[11],[1.0])|(6,[4],[1.0])|(4,[1],[1.0])|\n",
      "|  3|                23|               7|              4|      1|                   179|                             51|          18| 38|         239.554|        97|                   0|        1|  0|             1|            0|  0|    89|   170|             31|                        4|(28,[23],[1.0])|(6,[4],[1.0])|(4,[1],[1.0])|\n",
      "| 24|                14|               7|              6|      1|                   246|                             25|          16| 41|         239.554|        97|                   0|        1|  0|             1|            0|  0|    67|   170|             23|                        8|(28,[14],[1.0])|    (6,[],[])|(4,[1],[1.0])|\n",
      "|  3|                23|               7|              6|      1|                   179|                             51|          18| 38|         239.554|        97|                   0|        1|  0|             1|            0|  0|    89|   170|             31|                        2|(28,[23],[1.0])|    (6,[],[])|(4,[1],[1.0])|\n",
      "|  3|                21|               7|              2|      1|                   179|                             51|          18| 38|         239.554|        97|                   0|        1|  0|             1|            0|  0|    89|   170|             31|                        8|(28,[21],[1.0])|(6,[2],[1.0])|(4,[1],[1.0])|\n",
      "|  6|                11|               7|              5|      1|                   189|                             29|          13| 33|         239.554|        97|                   0|        1|  2|             0|            0|  2|    69|   167|             25|                        8|(28,[11],[1.0])|(6,[5],[1.0])|(4,[1],[1.0])|\n",
      "| 33|                23|               8|              4|      1|                   248|                             25|          14| 47|         205.917|        92|                   0|        1|  2|             0|            0|  1|    86|   165|             32|                        2|(28,[23],[1.0])|(6,[4],[1.0])|(4,[1],[1.0])|\n",
      "+---+------------------+----------------+---------------+-------+----------------------+-------------------------------+------------+---+----------------+----------+--------------------+---------+---+--------------+-------------+---+------+------+---------------+-------------------------+---------------+-------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create our encoder instance and save as onehot_encoder\n",
    "onehot_encoder = OneHotEncoder(inputCols=['Reason_for_absence', 'Day_of_the_week', 'Seasons'],\n",
    "                               outputCols=['Reason_onehot', 'Day_onehot', 'Season_onehot'])\n",
    "\n",
    "# Fit our encoder instance on our data frame and save it as encoder_transform\n",
    "encoder_trans = onehot_encoder.fit(absentee_data)\n",
    "\n",
    "# Test encoder_model by transforming our absentee_data and save as encoded\n",
    "encoded = encoder_trans.transform(absentee_data)\n",
    "\n",
    "# Check that everything looks as expected using the action .show()\n",
    "encoded.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be06d2af-fd94-4cc4-82cf-102c783c7dec",
   "metadata": {},
   "source": [
    "#### Vector Assemblers  \n",
    "\n",
    "The `vectorAssembler` will create a features vector containing all predictor variables that we want to use in our linear and KNN models that will used scaled data in addition to the one hot encoded variables and a couple of unchanged variables from our dataset. We will call this vector assembler `features_Assembler`. We need to pass these variable names as a list. To easiliy grab the columns we want we can use the `.columns` attribute on our spark SQL data frames to return a list of column names. We can then copy and paste the variables we want to include in our `features` column. We will include the variables:  \n",
    "\n",
    "`Transportation_expense_scaled`, `Distance_from_Residence_to_Work_scaled`, `Service_time_scaled`, `Age_scaled`, `Workload_per_day_scaled`, `Hit_target_scaled`, `Son_scaled`, `Pet_scaled`, `Weight_scaled`, `Height_scaled`, `Reason_onehot`, `Day_onehot`, `Season_onehot`, `Disciplinary_failure`, `Education`, `Social_drinker`, and`Social_smoker`.\n",
    "\n",
    "We will create a separate vector assembler to use with our tree models called `tree_features_assembler` and include the factors: \n",
    "\n",
    "`Transportation_expense`, `Distance_from_Residence_to_Work`, `Service_time`, `Age`, `Workload_per_day`, `Hit_target`, `Disciplinary_failure`, `Education`, `Son`, `Social_drinker`, `Social_smoker`, `Pet`, `Weight`, `Height`, `Reason_onehot`, `Day_onehot`, `Season_onehot`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f7db2d5f-a6b6-42a5-99ec-d9f04b4e7405",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ID', 'Reason_for_absence', 'Month_of_absence', 'Day_of_the_week', 'Seasons', 'Transportation_expense', 'Distance_from_Residence_to_Work', 'Service_time', 'Age', 'Workload_per_day', 'Hit_target', 'Disciplinary_failure', 'Education', 'Son', 'Social_drinker', 'Social_smoker', 'Pet', 'Weight', 'Height', 'Body_mass_index', 'Absenteeism_time_in_hours', 'Transportation_expense_vec', 'Distance_from_Residence_to_Work_vec', 'Service_time_vec', 'Age_vec', 'Workload_per_day_vec', 'Hit_target_vec', 'Son_vec', 'Pet_vec', 'Weight_vec', 'Height_vec', 'Transportation_expense_scaled', 'Distance_from_Residence_to_Work_scaled', 'Service_time_scaled', 'Age_scaled', 'Workload_per_day_scaled', 'Hit_target_scaled', 'Son_scaled', 'Pet_scaled', 'Weight_scaled', 'Height_scaled']\n"
     ]
    }
   ],
   "source": [
    "print(scale_trans.transform(absentee_data).columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3512365b-c9f5-4f75-a2fb-1a3ec42506e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ID', 'Reason_for_absence', 'Month_of_absence', 'Day_of_the_week', 'Seasons', 'Transportation_expense', 'Distance_from_Residence_to_Work', 'Service_time', 'Age', 'Workload_per_day', 'Hit_target', 'Disciplinary_failure', 'Education', 'Son', 'Social_drinker', 'Social_smoker', 'Pet', 'Weight', 'Height', 'Body_mass_index', 'Absenteeism_time_in_hours', 'Reason_onehot', 'Day_onehot', 'Season_onehot']\n"
     ]
    }
   ],
   "source": [
    "print(encoded.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "431a7335-96f9-4c4c-98d9-dd34e9a30632",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ID',\n",
       " 'Reason_for_absence',\n",
       " 'Month_of_absence',\n",
       " 'Day_of_the_week',\n",
       " 'Seasons',\n",
       " 'Transportation_expense',\n",
       " 'Distance_from_Residence_to_Work',\n",
       " 'Service_time',\n",
       " 'Age',\n",
       " 'Workload_per_day',\n",
       " 'Hit_target',\n",
       " 'Disciplinary_failure',\n",
       " 'Education',\n",
       " 'Son',\n",
       " 'Social_drinker',\n",
       " 'Social_smoker',\n",
       " 'Pet',\n",
       " 'Weight',\n",
       " 'Height',\n",
       " 'Body_mass_index',\n",
       " 'Absenteeism_time_in_hours']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "absentee_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "af303518-9b1f-4fac-953d-2f309d45f706",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_Assembler = VectorAssembler(inputCols = ['Transportation_expense_scaled', 'Distance_from_Residence_to_Work_scaled', 'Service_time_scaled', \\\n",
    "                                                        'Age_scaled', 'Workload_per_day_scaled', 'Hit_target_scaled', 'Son_scaled', 'Pet_scaled', \\\n",
    "                                                        'Weight_scaled', 'Height_scaled', 'Reason_onehot', 'Day_onehot', 'Season_onehot',  \\\n",
    "                                                        'Disciplinary_failure', 'Education', 'Social_drinker', 'Social_smoker'], \n",
    "                                  outputCol = 'features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8d435765-6ee3-44fe-8916-7240a86afe81",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_features_Assembler = VectorAssembler(inputCols = ['Reason_onehot', 'Day_onehot', 'Season_onehot', 'Transportation_expense', \\\n",
    "                                                       'Distance_from_Residence_to_Work', 'Service_time', 'Age', 'Workload_per_day', \\\n",
    "                                                       'Hit_target', 'Disciplinary_failure', 'Education', 'Son', 'Social_drinker', \\\n",
    "                                                       'Social_smoker', 'Pet', 'Weight', 'Height'], \n",
    "                                  outputCol = 'features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "e0f1f5c2-813b-4ec2-8dbb-d3b83d55e2c8",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------------+----------------+---------------+-------+----------------------+-------------------------------+------------+---+----------------+----------+--------------------+---------+---+--------------+-------------+---+------+------+---------------+-------------------------+--------------------+\n",
      "| ID|Reason_for_absence|Month_of_absence|Day_of_the_week|Seasons|Transportation_expense|Distance_from_Residence_to_Work|Service_time|Age|Workload_per_day|Hit_target|Disciplinary_failure|Education|Son|Social_drinker|Social_smoker|Pet|Weight|Height|Body_mass_index|Absenteeism_time_in_hours|            features|\n",
      "+---+------------------+----------------+---------------+-------+----------------------+-------------------------------+------------+---+----------------+----------+--------------------+---------+---+--------------+-------------+---+------+------+---------------+-------------------------+--------------------+\n",
      "| 11|                26|               7|              3|      1|                   289|                             36|          13| 33|         239.554|        97|                   0|        1|  2|             1|            0|  1|    90|   172|             30|                        4|[11.0,26.0,7.0,3....|\n",
      "| 36|                 0|               7|              3|      1|                   118|                             13|          18| 50|         239.554|        97|                   1|        1|  1|             1|            0|  0|    98|   178|             31|                        0|[36.0,0.0,7.0,3.0...|\n",
      "|  3|                23|               7|              4|      1|                   179|                             51|          18| 38|         239.554|        97|                   0|        1|  0|             1|            0|  0|    89|   170|             31|                        2|[3.0,23.0,7.0,4.0...|\n",
      "|  7|                 7|               7|              5|      1|                   279|                              5|          14| 39|         239.554|        97|                   0|        1|  2|             1|            1|  0|    68|   168|             24|                        4|[7.0,7.0,7.0,5.0,...|\n",
      "| 11|                23|               7|              5|      1|                   289|                             36|          13| 33|         239.554|        97|                   0|        1|  2|             1|            0|  1|    90|   172|             30|                        2|[11.0,23.0,7.0,5....|\n",
      "|  3|                23|               7|              6|      1|                   179|                             51|          18| 38|         239.554|        97|                   0|        1|  0|             1|            0|  0|    89|   170|             31|                        2|[3.0,23.0,7.0,6.0...|\n",
      "| 10|                22|               7|              6|      1|                   361|                             52|           3| 28|         239.554|        97|                   0|        1|  1|             1|            0|  4|    80|   172|             27|                        8|[10.0,22.0,7.0,6....|\n",
      "| 20|                23|               7|              6|      1|                   260|                             50|          11| 36|         239.554|        97|                   0|        1|  4|             1|            0|  0|    65|   168|             23|                        4|[20.0,23.0,7.0,6....|\n",
      "| 14|                19|               7|              2|      1|                   155|                             12|          14| 34|         239.554|        97|                   0|        1|  2|             1|            0|  0|    95|   196|             25|                       40|[14.0,19.0,7.0,2....|\n",
      "|  1|                22|               7|              2|      1|                   235|                             11|          14| 37|         239.554|        97|                   0|        3|  1|             0|            0|  1|    88|   172|             29|                        8|[1.0,22.0,7.0,2.0...|\n",
      "| 20|                 1|               7|              2|      1|                   260|                             50|          11| 36|         239.554|        97|                   0|        1|  4|             1|            0|  0|    65|   168|             23|                        8|[20.0,1.0,7.0,2.0...|\n",
      "| 20|                 1|               7|              3|      1|                   260|                             50|          11| 36|         239.554|        97|                   0|        1|  4|             1|            0|  0|    65|   168|             23|                        8|[20.0,1.0,7.0,3.0...|\n",
      "| 20|                11|               7|              4|      1|                   260|                             50|          11| 36|         239.554|        97|                   0|        1|  4|             1|            0|  0|    65|   168|             23|                        8|[20.0,11.0,7.0,4....|\n",
      "|  3|                11|               7|              4|      1|                   179|                             51|          18| 38|         239.554|        97|                   0|        1|  0|             1|            0|  0|    89|   170|             31|                        1|[3.0,11.0,7.0,4.0...|\n",
      "|  3|                23|               7|              4|      1|                   179|                             51|          18| 38|         239.554|        97|                   0|        1|  0|             1|            0|  0|    89|   170|             31|                        4|[3.0,23.0,7.0,4.0...|\n",
      "| 24|                14|               7|              6|      1|                   246|                             25|          16| 41|         239.554|        97|                   0|        1|  0|             1|            0|  0|    67|   170|             23|                        8|[24.0,14.0,7.0,6....|\n",
      "|  3|                23|               7|              6|      1|                   179|                             51|          18| 38|         239.554|        97|                   0|        1|  0|             1|            0|  0|    89|   170|             31|                        2|[3.0,23.0,7.0,6.0...|\n",
      "|  3|                21|               7|              2|      1|                   179|                             51|          18| 38|         239.554|        97|                   0|        1|  0|             1|            0|  0|    89|   170|             31|                        8|[3.0,21.0,7.0,2.0...|\n",
      "|  6|                11|               7|              5|      1|                   189|                             29|          13| 33|         239.554|        97|                   0|        1|  2|             0|            0|  2|    69|   167|             25|                        8|[6.0,11.0,7.0,5.0...|\n",
      "| 33|                23|               8|              4|      1|                   248|                             25|          14| 47|         205.917|        92|                   0|        1|  2|             0|            0|  1|    86|   165|             32|                        2|[33.0,23.0,8.0,4....|\n",
      "+---+------------------+----------------+---------------+-------+----------------------+-------------------------------+------------+---+----------------+----------+--------------------+---------+---+--------------+-------------+---+------+------+---------------+-------------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#create a feature array by omitting the last column\n",
    "feature_cols = absentee_data.columns[:-1]\n",
    "vect_assembler = VectorAssembler(inputCols = feature_cols, outputCol=\"features\")\n",
    "#Utilize Assembler created above in order to add the feature column\n",
    "data_w_features = vect_assembler.transform(absentee_data)\n",
    "data_w_features.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d58b95eb-23ee-413d-9c95-e362ecab7af3",
   "metadata": {},
   "source": [
    "### Model 1  - Multiple Linear Regression  \n",
    "\n",
    "We will use `LinearRegression` from `pyspark.ml.regression` for our MLR model. The parameters available allow for various types of regularization, including none (ordinary least squares), Ridge Regression, Lasso, and Elastic Net. The `regParam` represents the $\\lambda$ in the penalty part of the loss function (`elasticNetParam` range of 0 to 1). The series of transformations that we will use in our MLR pipeline are:  \n",
    "\n",
    "1. `sqlTransLabel` - To select the columns of interest from our original data frame and to create our `label` column for our target variable, `Absenteeism_time_in_hours`.  \n",
    "2.  `df_scale` - To standardize our numeric columns.  \n",
    "3.  `encoder_model` To create one hot encoded versions of our categorical variables.  \n",
    "4.  `features_Assembler` To put all of our desired predictor variables into our `features` vector.  \n",
    "5.  `mlr_regressor` To create our MLR model.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1b583a7b-29ea-4626-bb22-933ec6793dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing LinearRegression\n",
    "from pyspark.ml.regression import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bf0b71da-a9b8-49a6-bede-2f2e8afda0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating mlr regressor instance for pipeline\n",
    "mlr_regressor = LinearRegression(featuresCol = 'features', labelCol='label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "39b4be7c-e4a3-4aa0-96b1-9db467a17f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating mlr pipeline \n",
    "mlr_pipeline = Pipeline(stages = [sql_trans_label, scale_trans, encoder_trans, features_Assembler, mlr_regressor])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd34b06-caed-4106-8f0a-e05dfaef7cea",
   "metadata": {},
   "source": [
    "We can use `ParamGridBuilder()` to create a grid of all possible values of our parameters that we would like to consider for our model. Here we will select five values for `regParam` and five values for `elasticNetParam`. Note that each additional value included for a parameter when building the param grid will increase the computational time diring cross validation.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e4286273-2cef-4257-a0a4-b172f1374806",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating mlr param grid for cross validation\n",
    "mlr_paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(mlr_regressor.regParam, [0, 0.01, 0.1, 1.0, 10.0]) \\\n",
    "    .addGrid(mlr_regressor.elasticNetParam, [0.0, 0.2, 0.5, 0.7, 1.0]) \\\n",
    "    .build()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da2b9b9b-a368-4cf6-9316-fe942eca12bc",
   "metadata": {},
   "source": [
    "Next, we will create our MLR crossvalidator, `mlr_crossval`, using the `mlr_pipeline`, `mlr_paramgrid`, and using RMSE as our metric.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3aeb43ab-de3c-4871-b4ed-5abf15ff6eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating mlr crossvalidator using the mlr_pipleline, mlr_paramgrid, and using RMSE as our metric\n",
    "mlr_crossval = CrossValidator(estimator = mlr_pipeline,\n",
    "                              estimatorParamMaps = mlr_paramGrid,\n",
    "                              evaluator = RegressionEvaluator(metricName='rmse'),\n",
    "                              numFolds=5,\n",
    "                              seed = 1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a5d44b-8681-465d-8e69-6a504386aba5",
   "metadata": {},
   "source": [
    "We can now fit our model on our `train` data set using `mlr_crossval`. This will automatically select the optimal values for our `regParam` and `elasticNetParam` parameters. We will save this as `mlr_cv_model`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2be6c091-6987-4511-8fec-689b03b2b1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting model using the mlr cross validator that we created\n",
    "mlr_cv_model = mlr_crossval.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "47698378-f531-4386-822a-c53f32407400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best MLR Training RMSE: 11.923348668556022\n",
      "Best MLR Training MAE: 5.102668265393188\n",
      "regParam: regularization parameter (>= 0). (default: 0.0, current: 10.0)\n",
      "elasticNetParam: the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty. (default: 0.0, current: 0.0)\n",
      "[0.22564939580740787,-0.6252957576607703,-0.015777293799200762,0.2454562937554915,-0.14484956563201312,0.3204408029915885,0.8504410997700359,-0.32424344030453933,-0.06862145349098422,0.9099764622723966,-2.6574956624445485,3.710945882036456,9.655008294267649,0.7167025422106625,0.2668811810292204,-1.438637790992728,-0.08419063550457666,3.5350050397497625,-1.121249118850277,20.831941780091526,2.4025721961741247,2.7798154128636887,10.305868007015123,5.760164243153682,2.338809116092974,-1.1090962530608028,-3.186659236689783,1.414747324933591,0.3175929729162767,8.204818826352561,0.0,-0.2531439932882133,0.6707705853541583,-1.947262730852879,0.15712024147774156,-1.8126578140103635,-0.08791012029732032,-1.3312181407370633,0.0,0.0,1.3110492718409077,0.2977772889965644,0.5512748130667979,-1.2518821087220913,0.0,0.10957800910751682,-0.8707208703712691,0.3798914063174227,-2.408703410980148,-0.708956338530766,0.7099762956320012,0.02802495505242304]\n"
     ]
    }
   ],
   "source": [
    "# MLR model stats\n",
    "best_mlr_Pipeline = mlr_cv_model.bestModel\n",
    "best_mlr_Model = best_mlr_Pipeline.stages[4]\n",
    "print(f\"Best MLR Training RMSE: {best_mlr_Model.summary.rootMeanSquaredError}\")\n",
    "print(f\"Best MLR Training MAE: {best_mlr_Model.summary.meanAbsoluteError}\")\n",
    "print(best_mlr_Model.explainParam('regParam'))\n",
    "print(best_mlr_Model.explainParam('elasticNetParam'))\n",
    "print(best_mlr_Model.coefficients)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28969cd2-e45a-4d64-8455-879debda2e12",
   "metadata": {},
   "source": [
    "Next, we will run cross validation using MAE as our metric and see if both cross validators return the same model, or if different models were selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "90091319-4d03-4cfe-ae85-9dedf68ef593",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating mlr mae crossvalidator using the mlr_pipleline, mlr_paramgrid, and using RMSE as our metric\n",
    "mlr_mae_crossval = CrossValidator(estimator = mlr_pipeline,\n",
    "                                  estimatorParamMaps = mlr_paramGrid,\n",
    "                                  evaluator = RegressionEvaluator(metricName='mae'),\n",
    "                                  numFolds=5,\n",
    "                                  seed = 1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "872e4f5d-22e9-474e-a0cf-41f31304f64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting model using the mlr mae cross validator that we created\n",
    "mlr_mae_cv_model = mlr_mae_crossval.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e2bb63ac-4dfc-4088-8b5b-162612c0bc9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elasticNetParam: the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty. (default: 0.0, current: 0.0)\n",
      "regParam: regularization parameter (>= 0). (default: 0.0, current: 10.0)\n",
      "[0.22564939580740787,-0.6252957576607703,-0.015777293799200762,0.2454562937554915,-0.14484956563201312,0.3204408029915885,0.8504410997700359,-0.32424344030453933,-0.06862145349098422,0.9099764622723966,-2.6574956624445485,3.710945882036456,9.655008294267649,0.7167025422106625,0.2668811810292204,-1.438637790992728,-0.08419063550457666,3.5350050397497625,-1.121249118850277,20.831941780091526,2.4025721961741247,2.7798154128636887,10.305868007015123,5.760164243153682,2.338809116092974,-1.1090962530608028,-3.186659236689783,1.414747324933591,0.3175929729162767,8.204818826352561,0.0,-0.2531439932882133,0.6707705853541583,-1.947262730852879,0.15712024147774156,-1.8126578140103635,-0.08791012029732032,-1.3312181407370633,0.0,0.0,1.3110492718409077,0.2977772889965644,0.5512748130667979,-1.2518821087220913,0.0,0.10957800910751682,-0.8707208703712691,0.3798914063174227,-2.408703410980148,-0.708956338530766,0.7099762956320012,0.02802495505242304]\n"
     ]
    }
   ],
   "source": [
    "# MLR mae model params\n",
    "best_mlr_mae_Pipeline = mlr_mae_cv_model.bestModel\n",
    "best_mlr_mae_Model = best_mlr_mae_Pipeline.stages[4]\n",
    "print(best_mlr_mae_Model.explainParam('elasticNetParam'))\n",
    "print(best_mlr_mae_Model.explainParam('regParam'))\n",
    "print(best_mlr_mae_Model.coefficients)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "541c0276-568a-4a9c-9e0f-a485ddb467a0",
   "metadata": {},
   "source": [
    "Using RMSE and MAE in cross-validation ended up selecting the same model, with a value of `0` for the `elasticNetParam` and a value of `10` for the `regParam`. Note that since `0` was selected as the optimal value for the `elasticNetParam` the selected model is a ridge regression model, with a penalty of `10`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f628019-168a-471a-8fd6-36ddfb6f46e8",
   "metadata": {},
   "source": [
    "#### Evaluating CV Selected Model on Training Set  \n",
    "\n",
    "`LinearRegression` in `MLlib` makes it easy to find the training RMSE and MAE values when we use this in cross validation. The fitted linear regression model has an attribute, `summary` that will allow you to easiliy access statistics on residuals, MSE and r-squared values for your fitted model. We will use this to print our values for RMSE and MAE for our training set.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2051be7b-7442-4371-95bf-483929c2813e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best MLR (Ridge Regression) Training RMSE: 11.923348668556022\n",
      "Best MLR (Ridge Regression) Training MAE: 5.102668265393188\n"
     ]
    }
   ],
   "source": [
    "print(f\"Best MLR (Ridge Regression) Training RMSE: {best_mlr_Model.summary.rootMeanSquaredError}\")\n",
    "print(f\"Best MLR (Ridge Regression) Training MAE: {best_mlr_Model.summary.meanAbsoluteError}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db7dd16-76a0-4b7a-854f-812dc7ec4985",
   "metadata": {},
   "source": [
    "### Model 2  - Regression Tree  \n",
    "\n",
    "One benefit of regression trees is that there is not a need to scale the predictors in the model. As a result, we do not need to include this transformation in our regression tree pipeline. We still want to use our onehot encoder transformation to create dummy variables for the categorical variables in our model. We will use the `tree_features_Assembler` that we created above to create our features vector for our regression trees. We will be using `DecisionTreeRegressor` from `MLLib` for our model fitting.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2283a30b-99a7-4ed5-b28a-0c9ba09ab98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6547f0b4-71f3-48f6-9367-eef531384b99",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Creating regression tree regressor instance for pipeline\n",
    "single_tree_regressor = DecisionTreeRegressor(featuresCol = 'features', labelCol='label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "088a9fa4-0960-4bd7-9cf9-75e5fbe2e954",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating single regression tree pipeline \n",
    "single_tree_pipeline = Pipeline(stages = [sql_trans_label, encoder_trans, tree_features_Assembler, single_tree_regressor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "de75eb3a-dd88-44af-82d8-426b10b561aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating single regression tree param grid for cross validation\n",
    "single_tree_paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(single_tree_regressor.maxDepth, [5, 10, 15, 20, 25, 30]) \\\n",
    "    .addGrid(single_tree_regressor.minInstancesPerNode, [3, 5, 10, 50, 100]) \\\n",
    "    .build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "e1356211-1110-4265-b4eb-c408055e84e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating single regression tree crossvalidator using the single_tree_pipleline, single_tree_paramgrid, and using RMSE as our metric\n",
    "single_tree_crossval = CrossValidator(estimator = single_tree_pipeline,\n",
    "                                      estimatorParamMaps = single_tree_paramGrid,\n",
    "                                      evaluator = RegressionEvaluator(metricName='rmse'),\n",
    "                                      numFolds=5,\n",
    "                                      seed = 1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "6d52b2fd-b20f-4d28-85a0-76521ec8b6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting model using the single tree cross validator that we created\n",
    "single_tree_cv_model = single_tree_crossval.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "e1581ee1-7c72-4a70-a827-2fce89ea5692",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maxDepth: Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30]. (default: 5, current: 5)\n",
      "minInstancesPerNode: Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1. (default: 1, current: 10)\n"
     ]
    }
   ],
   "source": [
    "# Single Regression Tree model stats\n",
    "best_single_tree_Pipeline = single_tree_cv_model.bestModel\n",
    "best_single_tree_Model = best_single_tree_Pipeline.stages[3]\n",
    "print(best_single_tree_Model.explainParam('maxDepth'))\n",
    "print(best_single_tree_Model.explainParam('minInstancesPerNode'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "e6fe11a4-88ed-4020-ab2b-8707d4f22e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating single regression tree mae crossvalidator using the single_tree_pipleline, single_tree_paramgrid, and using RMSE as our metric\n",
    "single_tree_mae_crossval = CrossValidator(estimator = single_tree_pipeline,\n",
    "                                          estimatorParamMaps = single_tree_paramGrid,\n",
    "                                          evaluator = RegressionEvaluator(metricName='mae'),\n",
    "                                          numFolds=5,\n",
    "                                          seed = 1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "ce299117-9b6b-43e2-b539-0c01e1e745d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting model using the single tree mae cross validator that we created\n",
    "single_tree_mae_cv_model = single_tree_mae_crossval.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "07df18f3-80b2-45e1-8dbd-04d48943b0d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maxDepth: Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30]. (default: 5, current: 15)\n",
      "minInstancesPerNode: Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1. (default: 1, current: 3)\n"
     ]
    }
   ],
   "source": [
    "# Single Regression Tree mae model stats\n",
    "best_single_tree_mae_Pipeline = single_tree_mae_cv_model.bestModel\n",
    "best_single_tree_mae_Model = best_single_tree_mae_Pipeline.stages[3]\n",
    "print(best_single_tree_mae_Model.explainParam('maxDepth'))\n",
    "print(best_single_tree_mae_Model.explainParam('minInstancesPerNode'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e5a742a-f296-4833-a2bc-fbab3af84702",
   "metadata": {},
   "source": [
    "Cross-validation using RMSE both selected a decision tree model with `5` for `maxDepth` and `10` for `minInstancesPerNode`. Cross validation using MAE selected a decision tree model with `15` for `maxDepth` and `3` for `minInstancesPerNode`. We can use `.toDebugString` to get a full description of each model. This will allow us to compare the complexity of the model created using RMSE to the model created using MAE. We want to ovoid overfitting our model on our training data, as this generally reduces the model's performance on data that was not used to train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "17432988-cf10-4144-84d9-8183c27583cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE CV regression tree model selected:\n",
      "\n",
      "DecisionTreeRegressionModel: uid=DecisionTreeRegressor_9cf0625916b9, depth=5, numNodes=21, numFeatures=52\n",
      "  If (feature 19 in {0.0})\n",
      "   If (feature 13 in {0.0})\n",
      "    If (feature 51 <= 190.5)\n",
      "     If (feature 0 in {1.0})\n",
      "      Predict: 0.0\n",
      "     Else (feature 0 not in {1.0})\n",
      "      If (feature 40 <= 16.5)\n",
      "       Predict: 6.1454545454545455\n",
      "      Else (feature 40 > 16.5)\n",
      "       Predict: 3.025\n",
      "    Else (feature 51 > 190.5)\n",
      "     Predict: 14.764705882352942\n",
      "   Else (feature 13 not in {0.0})\n",
      "    If (feature 39 <= 18.5)\n",
      "     Predict: 33.27272727272727\n",
      "    Else (feature 39 > 18.5)\n",
      "     If (feature 47 <= 0.5)\n",
      "      Predict: 3.2\n",
      "     Else (feature 47 > 0.5)\n",
      "      If (feature 38 <= 240.5)\n",
      "       Predict: 11.5\n",
      "      Else (feature 38 > 240.5)\n",
      "       Predict: 18.75\n",
      "  Else (feature 19 not in {0.0})\n",
      "   If (feature 49 <= 1.5)\n",
      "    If (feature 43 <= 96.5)\n",
      "     Predict: 15.0\n",
      "    Else (feature 43 > 96.5)\n",
      "     Predict: 40.0\n",
      "   Else (feature 49 > 1.5)\n",
      "    Predict: 6.9\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'RMSE CV regression tree model selected:\\n\\n{best_single_tree_Model.toDebugString}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "1f8d2d43-37cb-4ba6-a07b-44b65684ac8f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE CV regression tree model selected:\n",
      "\n",
      "DecisionTreeRegressionModel: uid=DecisionTreeRegressor_9cf0625916b9, depth=15, numNodes=143, numFeatures=52\n",
      "  If (feature 19 in {0.0})\n",
      "   If (feature 9 in {0.0})\n",
      "    If (feature 13 in {0.0})\n",
      "     If (feature 12 in {0.0})\n",
      "      If (feature 51 <= 190.5)\n",
      "       If (feature 1 in {0.0})\n",
      "        If (feature 0 in {1.0})\n",
      "         Predict: 0.0\n",
      "        Else (feature 0 not in {1.0})\n",
      "         If (feature 38 <= 264.0)\n",
      "          If (feature 26 in {0.0})\n",
      "           If (feature 22 in {0.0})\n",
      "            If (feature 10 in {0.0})\n",
      "             If (feature 18 in {0.0})\n",
      "              If (feature 11 in {0.0})\n",
      "               If (feature 6 in {0.0})\n",
      "                If (feature 14 in {0.0})\n",
      "                 Predict: 2.819277108433735\n",
      "                Else (feature 14 not in {0.0})\n",
      "                 Predict: 5.142857142857143\n",
      "               Else (feature 6 not in {0.0})\n",
      "                Predict: 6.75\n",
      "              Else (feature 11 not in {0.0})\n",
      "               If (feature 41 <= 29.5)\n",
      "                Predict: 9.8\n",
      "               Else (feature 41 > 29.5)\n",
      "                If (feature 30 in {0.0})\n",
      "                 Predict: 3.75\n",
      "                Else (feature 30 not in {0.0})\n",
      "                 Predict: 6.25\n",
      "             Else (feature 18 not in {0.0})\n",
      "              If (feature 32 in {1.0})\n",
      "               Predict: 4.0\n",
      "              Else (feature 32 not in {1.0})\n",
      "               If (feature 36 in {1.0})\n",
      "                Predict: 6.333333333333333\n",
      "               Else (feature 36 not in {1.0})\n",
      "                Predict: 8.0\n",
      "            Else (feature 10 not in {0.0})\n",
      "             If (feature 50 <= 67.5)\n",
      "              Predict: 13.333333333333334\n",
      "             Else (feature 50 > 67.5)\n",
      "              If (feature 43 <= 91.5)\n",
      "               Predict: 4.333333333333333\n",
      "              Else (feature 43 > 91.5)\n",
      "               Predict: 7.0\n",
      "           Else (feature 22 not in {0.0})\n",
      "            If (feature 51 <= 168.5)\n",
      "             Predict: 10.666666666666666\n",
      "            Else (feature 51 > 168.5)\n",
      "             If (feature 39 <= 15.5)\n",
      "              Predict: 8.0\n",
      "             Else (feature 39 > 15.5)\n",
      "              Predict: 6.333333333333333\n",
      "          Else (feature 26 not in {0.0})\n",
      "           If (feature 40 <= 13.5)\n",
      "            If (feature 36 in {0.0})\n",
      "             If (feature 35 in {1.0})\n",
      "              Predict: 6.4\n",
      "             Else (feature 35 not in {1.0})\n",
      "              Predict: 8.0\n",
      "            Else (feature 36 not in {0.0})\n",
      "             Predict: 10.666666666666666\n",
      "           Else (feature 40 > 13.5)\n",
      "            Predict: 5.6\n",
      "         Else (feature 38 > 264.0)\n",
      "          If (feature 7 in {0.0})\n",
      "           If (feature 14 in {0.0})\n",
      "            If (feature 41 <= 36.5)\n",
      "             If (feature 47 <= 0.5)\n",
      "              If (feature 43 <= 93.5)\n",
      "               Predict: 14.0\n",
      "              Else (feature 43 > 93.5)\n",
      "               If (feature 31 in {1.0})\n",
      "                Predict: 5.666666666666667\n",
      "               Else (feature 31 not in {1.0})\n",
      "                Predict: 8.0\n",
      "             Else (feature 47 > 0.5)\n",
      "              If (feature 23 in {1.0})\n",
      "               If (feature 42 <= 253.711)\n",
      "                Predict: 1.2\n",
      "               Else (feature 42 > 253.711)\n",
      "                Predict: 4.0\n",
      "              Else (feature 23 not in {1.0})\n",
      "               If (feature 36 in {1.0})\n",
      "                If (feature 22 in {1.0})\n",
      "                 Predict: 4.666666666666667\n",
      "                Else (feature 22 not in {1.0})\n",
      "                 Predict: 6.5\n",
      "               Else (feature 36 not in {1.0})\n",
      "                If (feature 42 <= 240.515)\n",
      "                 Predict: 6.818181818181818\n",
      "                Else (feature 42 > 240.515)\n",
      "                 Predict: 7.7\n",
      "            Else (feature 41 > 36.5)\n",
      "             If (feature 36 in {0.0})\n",
      "              If (feature 42 <= 265.31600000000003)\n",
      "               If (feature 33 in {1.0})\n",
      "                If (feature 42 <= 238.5325)\n",
      "                 Predict: 1.75\n",
      "                Else (feature 42 > 238.5325)\n",
      "                 Predict: 3.75\n",
      "               Else (feature 33 not in {1.0})\n",
      "                Predict: 6.666666666666667\n",
      "              Else (feature 42 > 265.31600000000003)\n",
      "               If (feature 42 <= 289.53499999999997)\n",
      "                If (feature 33 in {0.0})\n",
      "                 Predict: 1.4\n",
      "                Else (feature 33 not in {0.0})\n",
      "                 Predict: 1.6666666666666667\n",
      "               Else (feature 42 > 289.53499999999997)\n",
      "                If (feature 42 <= 307.46900000000005)\n",
      "                 Predict: 3.75\n",
      "                Else (feature 42 > 307.46900000000005)\n",
      "                 Predict: 2.0\n",
      "             Else (feature 36 not in {0.0})\n",
      "              Predict: 6.8\n",
      "           Else (feature 14 not in {0.0})\n",
      "            If (feature 30 in {0.0})\n",
      "             Predict: 7.666666666666667\n",
      "            Else (feature 30 not in {0.0})\n",
      "             Predict: 26.666666666666668\n",
      "          Else (feature 7 not in {0.0})\n",
      "           Predict: 20.0\n",
      "       Else (feature 1 not in {0.0})\n",
      "        If (feature 39 <= 25.5)\n",
      "         If (feature 38 <= 240.5)\n",
      "          Predict: 5.666666666666667\n",
      "         Else (feature 38 > 240.5)\n",
      "          Predict: 8.0\n",
      "        Else (feature 39 > 25.5)\n",
      "         Predict: 25.666666666666668\n",
      "      Else (feature 51 > 190.5)\n",
      "       If (feature 30 in {0.0})\n",
      "        If (feature 37 in {1.0})\n",
      "         Predict: 2.25\n",
      "        Else (feature 37 not in {1.0})\n",
      "         If (feature 42 <= 307.46900000000005)\n",
      "          Predict: 4.0\n",
      "         Else (feature 42 > 307.46900000000005)\n",
      "          Predict: 6.666666666666667\n",
      "       Else (feature 30 not in {0.0})\n",
      "        If (feature 42 <= 307.46900000000005)\n",
      "         Predict: 51.25\n",
      "        Else (feature 42 > 307.46900000000005)\n",
      "         Predict: 1.6666666666666667\n",
      "     Else (feature 12 not in {0.0})\n",
      "      If (feature 39 <= 26.5)\n",
      "       Predict: 43.666666666666664\n",
      "      Else (feature 39 > 26.5)\n",
      "       Predict: 2.6666666666666665\n",
      "    Else (feature 13 not in {0.0})\n",
      "     If (feature 41 <= 47.5)\n",
      "      If (feature 38 <= 290.0)\n",
      "       If (feature 47 <= 0.5)\n",
      "        If (feature 43 <= 95.5)\n",
      "         If (feature 40 <= 10.5)\n",
      "          If (feature 42 <= 289.53499999999997)\n",
      "           Predict: 3.5\n",
      "          Else (feature 42 > 289.53499999999997)\n",
      "           Predict: 4.0\n",
      "         Else (feature 40 > 10.5)\n",
      "          Predict: 10.666666666666666\n",
      "        Else (feature 43 > 95.5)\n",
      "         If (feature 43 <= 96.5)\n",
      "          Predict: 2.6666666666666665\n",
      "         Else (feature 43 > 96.5)\n",
      "          If (feature 42 <= 238.5325)\n",
      "           Predict: 1.6666666666666667\n",
      "          Else (feature 42 > 238.5325)\n",
      "           Predict: 1.3333333333333333\n",
      "       Else (feature 47 > 0.5)\n",
      "        If (feature 42 <= 319.99199999999996)\n",
      "         If (feature 39 <= 21.0)\n",
      "          Predict: 16.0\n",
      "         Else (feature 39 > 21.0)\n",
      "          Predict: 8.0\n",
      "        Else (feature 42 > 319.99199999999996)\n",
      "         If (feature 32 in {1.0})\n",
      "          Predict: 16.6\n",
      "         Else (feature 32 not in {1.0})\n",
      "          Predict: 26.666666666666668\n",
      "      Else (feature 38 > 290.0)\n",
      "       Predict: 40.25\n",
      "     Else (feature 41 > 47.5)\n",
      "      Predict: 47.0\n",
      "   Else (feature 9 not in {0.0})\n",
      "    Predict: 42.0\n",
      "  Else (feature 19 not in {0.0})\n",
      "   If (feature 49 <= 1.5)\n",
      "    If (feature 43 <= 98.5)\n",
      "     If (feature 40 <= 11.5)\n",
      "      Predict: 38.6\n",
      "     Else (feature 40 > 11.5)\n",
      "      If (feature 35 in {0.0})\n",
      "       If (feature 33 in {0.0})\n",
      "        If (feature 36 in {0.0})\n",
      "         Predict: 8.0\n",
      "        Else (feature 36 not in {0.0})\n",
      "         Predict: 10.666666666666666\n",
      "       Else (feature 33 not in {0.0})\n",
      "        Predict: 14.333333333333334\n",
      "      Else (feature 35 not in {0.0})\n",
      "       If (feature 43 <= 97.5)\n",
      "        Predict: 24.0\n",
      "       Else (feature 43 > 97.5)\n",
      "        Predict: 18.666666666666668\n",
      "    Else (feature 43 > 98.5)\n",
      "     Predict: 66.66666666666667\n",
      "   Else (feature 49 > 1.5)\n",
      "    If (feature 45 <= 1.5)\n",
      "     Predict: 8.0\n",
      "    Else (feature 45 > 1.5)\n",
      "     Predict: 4.333333333333333\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'MAE CV regression tree model selected:\\n\\n{best_single_tree_mae_Model.toDebugString}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c9c8da4-37b3-4aef-b2e9-67773f10aa40",
   "metadata": {},
   "source": [
    "When we look at the full model descriptions we can see that the model selected via mean absolute error is much more complex than what was selected using RMSE. To avoid overfitting our single regression tree model to our training set, we will use the model selected using RMSE during cross validation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "887e9155-7a2d-4293-962b-525aa4a98896",
   "metadata": {},
   "source": [
    "#### Evaluating CV Selected Model on Training Set  \n",
    "\n",
    "Unfortunately, the `DecisionTreeRegerssionModel` in `MLlib` does not have the `summary` attribute, so we need a few steps to print the RMSE and MAE for our training set. We will use `RegressionEvaluator` to help get these values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "40929a8c-caef-4984-8e88-82dea07373cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "srt_train = single_tree_cv_model.transform(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "5b10cb93-9b42-417b-9c3a-fdabd19e3709",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single Regression Tree Training  RMSE: 11.742741107390424\n",
      "Single Regression Tree Training MAE: 5.075556158936739\n"
     ]
    }
   ],
   "source": [
    "# We can use regression_eval for all of our regression evaluators going forward\n",
    "regression_eval = RegressionEvaluator(labelCol = 'label')\n",
    "srt_train_rmse = regression_eval.evaluate(srt_train, {regression_eval.metricName:'rmse'})\n",
    "srt_train_mae = regression_eval.evaluate(srt_train,{regression_eval.metricName:'mae'})\n",
    "\n",
    "print(f\"Single Regression Tree Training  RMSE: {srt_train_rmse}\")\n",
    "print(f\"Single Regression Tree Training MAE: {srt_train_mae}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63c1208-dd62-447a-af13-a86c69d80e9a",
   "metadata": {},
   "source": [
    "So, we can see that our single tree regression model performed slightly better than our penalized MLR (Ridge Regression) model based on RMSE (11.74 vs 11.92) on our training set and MAE (5.08 vs 5.10). However, we really want to compare model performace on the test set, which we will do in our [Model Testing](#Model-Testing) section."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a5af89-1dc9-481f-928a-bf0d33ac1e79",
   "metadata": {},
   "source": [
    "### Model 3 - Random Forest  \n",
    "\n",
    "We will use the same set of transformations on in our random forest pipeline as we did with our single regression tree pipeline, this time using the `RandomForestRegressor` as our last stage in the pipeline. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "0e290c63-3aba-49b5-867a-7972b4f6bffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "4a609ee0-77f6-4040-bd73-1f270f04ccac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating random forest regressor instance for pipeline\n",
    "rf_regressor = RandomForestRegressor(featuresCol = 'features', labelCol='label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "33c5c4ee-bb43-4df9-8be8-8c6a7294595d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating random forest pipeline using all_vars_vectorAssembler and rf_regressor\n",
    "rf_pipeline = Pipeline(stages = [sql_trans_label, encoder_trans, tree_features_Assembler, rf_regressor])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a3ded6-9e3e-4309-8948-49440a761c60",
   "metadata": {},
   "source": [
    "#### Parameters for Random Forest Model  \n",
    "\n",
    "There are several possible parameters available for a building the random forest model using `RandomForestRegressor()`. We will specify values/possible values for three parameters, `numTrees`, `featureSubsetStrategy`, and `maxDepth`.  \n",
    "\n",
    "1.  The `numTrees` parameter - This parameter has a default value of `20` trees. By increasing this value we can bring down the variance in our model as compared to the single regression tree. We will set this value to `100` for our models.  \n",
    "2.  The `featureSubsetStrategy` parameter - This parameter is the number of features to consider for splits at each tree mode.  Possible values for this parameter are:\n",
    "    - `auto` - When this parameter is set to `auto` the number of features will automatically be selected based on the number of trees and the type of model. Our model is a regression model with `100` trees, and as a result `onethird` would be selected automatically. Note that `auto` is the default value for `featureSubsetStrategy`.  \n",
    "    - `all` - Use all features. If this is selected `RandomForestRegressor()` generates a bagged tree model as opposed to a random forest model.   \n",
    "    - `onethird` - The number of features to consider for splits at each tree node will be the total number of features in our model divided by three.  This is usually used for regression problems.  \n",
    "    - `sqrt` - This will use the square root of the number of features for the number of features to consider. This is usually used for classification problems.  \n",
    "    - `log2` - \n",
    "3.  The `maxDepth` parameter - This is the value for the maximum depth of the tree, and can have values ranging from `0` to `30`, with a default value of `5`. The possible values of `maxDepth` that we will use during model selection are `5`, `10`, `15`, `20`, and `25`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "0c949d69-c6cd-4e7f-aeae-1eb91e019e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating param grid for cross validation\n",
    "rf_paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(rf_regressor.numTrees, [100]) \\\n",
    "    .addGrid(rf_regressor.featureSubsetStrategy, ['onethird', 'sqrt', 'log2']) \\\n",
    "    .addGrid(rf_regressor.maxDepth, [5, 10, 15, 20, 25, 30]) \\\n",
    "    .build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "003d2657-4df1-47fb-ba35-1b38dbbe41a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating random forest crossvalidator\n",
    "rf_crossval = CrossValidator(estimator = rf_pipeline,\n",
    "                          estimatorParamMaps = rf_paramGrid,\n",
    "                          evaluator = RegressionEvaluator(metricName='rmse'),\n",
    "                          numFolds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "154b6cec-6576-40dd-802d-16b2c98ea8bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Fitting model using the random forest cross validator that we created\n",
    "rf_cv_model = rf_crossval.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "a25b15ea-6fee-42da-961b-40f43afadfda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best RMSE Random Forest Model Max Depth: 15\n",
      "Best RMSE Random Forest Model Feature Subset: sqrt\n"
     ]
    }
   ],
   "source": [
    "best_rf_Pipeline = rf_cv_model.bestModel\n",
    "best_rf_Model = best_rf_Pipeline.stages[3]\n",
    "print(f\"Best RMSE Random Forest Model Max Depth: {best_rf_Model.getMaxDepth()}\")\n",
    "print(f\"Best RMSE Random Forest Model Feature Subset: {best_rf_Model.getFeatureSubsetStrategy()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "b4bfb130-0227-4b74-8a34-e63a37e81800",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating random forest mae crossvalidator\n",
    "rf_mae_crossval = CrossValidator(estimator = rf_pipeline,\n",
    "                                 estimatorParamMaps = rf_paramGrid,\n",
    "                                 evaluator = RegressionEvaluator(metricName='mae'),\n",
    "                                 numFolds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "c20559e3-4b55-4364-afa7-47836422f55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting model using the random forest mae cross validator that we created\n",
    "rf_mae_cv_model = rf_mae_crossval.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "77b68053-dda3-4578-a44d-1653777ca692",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best MAE Random Forest Model Max Depth: 30\n",
      "Best MAE Random Forest Model Feature Subset: onethird\n"
     ]
    }
   ],
   "source": [
    "best_rf_mae_Pipeline = rf_mae_cv_model.bestModel\n",
    "best_rf_mae_Model = best_rf_mae_Pipeline.stages[3]\n",
    "print(f\"Best MAE Random Forest Model Max Depth: {best_rf_mae_Model.getMaxDepth()}\")\n",
    "print(f\"Best MAE Random Forest Model Feature Subset: {best_rf_mae_Model.getFeatureSubsetStrategy()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "e80ce112-3a8a-48f6-9cf4-09c391dcdf82",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "feature_list = ['ID',\n",
    " 'Reason_for_absence',\n",
    " 'Month_of_absence',\n",
    " 'Day_of_the_week',\n",
    " 'Seasons',\n",
    " 'Transportation_expense',\n",
    " 'Distance_from_Residence_to_Work',\n",
    " 'Service_time',\n",
    " 'Age',\n",
    " 'Work_load_Average/day_',\n",
    " 'Hit_target',\n",
    " 'Disciplinary_failure',\n",
    " 'Education',\n",
    " 'Son',\n",
    " 'Social_drinker',\n",
    " 'Social_smoker',\n",
    " 'Pet',\n",
    " 'Weight',\n",
    " 'Height',\n",
    " 'Body_mass_index']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1930c31f-c525-4a9b-9d94-ee838fb7d6f2",
   "metadata": {},
   "source": [
    "We can see that cross validation selected slightly different models based on RMSE vs MAE.  \n",
    "\n",
    "- The RMSE model selected `sqrt` for the `featureSubsetStrategy` and `15` as the `maxDepth`  \n",
    "- The MAE model selected `onethird` for the `featureSubsetStrategy` and `30` as the `maxDepth`  \n",
    "\n",
    "As discussed earlier, RMSE tends to penalize outliers more heavily than MAE. In this case, I want to build a model that will penalize outliers, so I will select the `rf_cv_model` that was selected based on best RMSE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e52259-a25e-48f8-8fb4-ff9bd41e7b44",
   "metadata": {},
   "source": [
    "#### Evaluating CV Selected Model on Training Set  \n",
    "\n",
    "Like the single regression tree, there are a couple of steps that we need to go through to get values for training RMSE and MAE. We will again use `RegressionEvaluator` to help get these values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "2e85d7df-f462-4319-b740-439bbf303917",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_train = rf_cv_model.transform(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8114c388-3972-4b43-82db-aac13a06c5d1",
   "metadata": {},
   "source": [
    "Now, let's look at the training RMSE and MAE for the fitted random forest model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "004deabb-aa34-40c5-b9ec-2d6ddc8585ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Training  RMSE: 6.370646025700593\n",
      "Random Forest Training MAE: 2.7237058352186043\n"
     ]
    }
   ],
   "source": [
    "rf_train_rmse = regression_eval.evaluate(rf_train, {regression_eval.metricName:'rmse'})\n",
    "rf_train_mae = regression_eval.evaluate(rf_train,{regression_eval.metricName:'mae'})\n",
    "\n",
    "print(f\"Random Forest Training  RMSE: {rf_train_rmse}\")\n",
    "print(f\"Random Forest Training MAE: {rf_train_mae}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c519cb1f-908c-4045-a39e-5013b80f7178",
   "metadata": {},
   "source": [
    "We can see that of the models so far, the random forest model (selected via cross-validation based on RMSE) has performed the best on the training data out of the model classes considered so far. This gives us an idea of how our model performed at predictions based on data that were used to train the model. We are most concerned with how our models generalize to data not included in training the model, and in the  [Model Testing](#Model-Testing) section we will see how each of our models performs on new data in order to determine the best model overall."
   ]
  },
  {
   "cell_type": "raw",
   "id": "d3435a12-66c0-4ea2-b58f-ad8e29272448",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "e7049afd-3636-4605-9def-a4c497d5218c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bebf1b8c-1825-41f5-867e-37b33618326e",
   "metadata": {},
   "source": [
    "### Model 4  - Gradient Boosted Regression Tree  \n",
    "\n",
    "We can use the same basic pipeline as we did for our other tree models. For cross validation, we will set up a parameter grid based on values for the `maxDepth` and `maxIter` parameters. The `maxDepth` parameter specifies the maximum depth of each regression tree and can have values from `0` to `30`, with a default value of `5`. The `maxIter` parameter specifies the maximum number of trees and must be set to a value greater than or equal to `0`, with a default value of `20`. We will use the default value for the shrinkage parameter, `stepSize`, of `0.1`. As noted earlier, `MLlib` also allows to use only a subset of features at each split, similar to a random forest model, using the `featureSubsetStrategy`. The default setting for this parameter is `all`, meaning all features will be considered at each split. We will use this default value for our boosted tree model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5718804c-13aa-4816-8b88-1a331a58ab15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import GBTRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d3732c55-0240-441f-8e11-acd4453dbe4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating gradient boosted tree regressor instance for pipeline\n",
    "gbt_regressor = GBTRegressor(featuresCol = 'features', labelCol='label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a53382aa-19d2-4bed-bce7-63f6e175cfca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating gbt pipeline \n",
    "gbt_pipeline = Pipeline(stages = [sql_trans_label, encoder_trans, tree_features_Assembler, gbt_regressor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "47321f3d-0578-4655-9aab-76abc24da1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating gbt param grid for cross validation\n",
    "gbt_paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(gbt_regressor.maxDepth, [3, 5, 10]) \\\n",
    "    .addGrid(gbt_regressor.maxIter, [5, 10, 20]) \\\n",
    "    .build()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c538272-7e02-4674-bb0a-6285cd746aca",
   "metadata": {},
   "source": [
    "#### Gradient Boosted Tree Cross Validation Using RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "491168f5-a7e9-4aa0-9045-eb42d5349973",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating gbt crossvalidator using the gbt_pipleline, gbt_paramgrid, and using RMSE as our metric\n",
    "gbt_crossval = CrossValidator(estimator = gbt_pipeline,\n",
    "                              estimatorParamMaps = gbt_paramGrid,\n",
    "                              evaluator = RegressionEvaluator(metricName='rmse'),\n",
    "                              numFolds=5,\n",
    "                              seed = 1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "8b7aae62-ac44-4c99-907a-3c3639ccfe17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting model using the gbt cross validator that we created\n",
    "gbt_cv_model = gbt_crossval.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8097b42b-f624-4696-b83e-870fd3104e48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "9123aa40-f3e8-4fef-8932-5e5d5ce3fd78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best RMSE GBT Model Max Depth: 3\n",
      "Best RMSE GBT Model Feature Subset: all\n",
      "Best RMSE GBT Model Max Iterations: 10\n"
     ]
    }
   ],
   "source": [
    "best_gbt_Pipeline = gbt_cv_model.bestModel\n",
    "best_gbt_Model = best_gbt_Pipeline.stages[3]\n",
    "print(f\"Best RMSE GBT Model Max Depth: {best_gbt_Model.getMaxDepth()}\")\n",
    "print(f\"Best RMSE GBT Model Feature Subset: {best_gbt_Model.getFeatureSubsetStrategy()}\")\n",
    "print(f\"Best RMSE GBT Model Max Iterations: {best_gbt_Model.getMaxIter()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e61b59-f775-493c-8d7d-7c68e8895fd2",
   "metadata": {},
   "source": [
    "#### Gradient Boosted Tree Cross Validation Using MAE  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "6cb9ca11-9dab-4bc2-932a-49cb1c848916",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating gbt mae crossvalidator using the gbt_pipleline, gbt_paramgrid, and using MAE as our metric\n",
    "gbt_mae_crossval = CrossValidator(estimator = gbt_pipeline,\n",
    "                                  estimatorParamMaps = gbt_paramGrid,\n",
    "                                  evaluator = RegressionEvaluator(metricName='mae'),\n",
    "                                  numFolds=5,\n",
    "                                  seed = 1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "fc84d072-fe15-456e-a03d-93ec11c47d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting model using the gbt mae cross validator that we created\n",
    "gbt_mae_cv_model = gbt_crossval.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "cb5a7c26-45b4-4a9f-8ba2-5570977ac05c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best MAE GBT Model Max Depth: 3\n",
      "Best MAE GBT Model Feature Subset: all\n",
      "Best MAE GBT Model Max Iterations: 10\n"
     ]
    }
   ],
   "source": [
    "best_gbt_mae_Pipeline = gbt_mae_cv_model.bestModel\n",
    "best_gbt_mae_Model = best_gbt_mae_Pipeline.stages[3]\n",
    "print(f\"Best MAE GBT Model Max Depth: {best_gbt_mae_Model.getMaxDepth()}\")\n",
    "print(f\"Best MAE GBT Model Feature Subset: {best_gbt_mae_Model.getFeatureSubsetStrategy()}\")\n",
    "print(f\"Best MAE GBT Model Max Iterations: {best_gbt_mae_Model.getMaxIter()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce3612b8-8c7b-4736-a13c-2b7120aed02f",
   "metadata": {},
   "source": [
    "Cross validation using RMSE and cross validation using MAE both selected a `maxDepth` of `3` and `maxIter` of `10`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048c7ae5-2579-4d3c-a3db-e3c73ea01827",
   "metadata": {},
   "source": [
    "#### Evaluating GBT CV Selected Model on Training Set  \n",
    "\n",
    "Like the single regression tree, and random forest models, there are a couple of steps that we need to go through to get values for training RMSE and MAE. We will again use `RegressionEvaluator` to help get these values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "29bf0c0e-1093-4898-90e9-76666b931650",
   "metadata": {},
   "outputs": [],
   "source": [
    "gbt_train = gbt_cv_model.transform(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "0a5643b5-b0fb-4824-8639-4bdf8b672b0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBT Training  RMSE: 8.76280715230066\n",
      "GBT Training MAE: 4.383497016058646\n"
     ]
    }
   ],
   "source": [
    "gbt_train_rmse = regression_eval.evaluate(gbt_train, {regression_eval.metricName:'rmse'})\n",
    "gbt_train_mae = regression_eval.evaluate(gbt_train,{regression_eval.metricName:'mae'})\n",
    "\n",
    "print(f\"GBT Training  RMSE: {gbt_train_rmse}\")\n",
    "print(f\"GBT Training MAE: {gbt_train_mae}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e5d694b-6dd2-4d36-9d1d-c6f14628576e",
   "metadata": {},
   "source": [
    "So we can see that our gradient boosted tree model performed slightly worse on the training set than our random forest model, but better than model 1 (MLR- ridge regression) and model 2 (single regression tree). Again, we want to compare our models based on the test set to determine which model is the best overall."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f1fed4-fcb1-410d-bee6-ac43b3ac0a7f",
   "metadata": {},
   "source": [
    "### Model 5 - LASSO Regression Model  \n",
    "\n",
    "We can fit a lasso regression model by using `LinearRegression` and specifying a value of `1` for the `ealsticNetParam`. We can then do cross validation using a range of penalties for the `regParam` parameter. For this model all basic transformations will be the same as those for the MLR model above.  \n",
    "\n",
    "Here we will allow for more possible values for our `regParam` than we did in Model 1. Since we are setting the value of the `elasticNetParam` to `1` we will set more values for the `regParam` than we did in Model 1 without adding additional computational time to cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8c9cde05-b48f-44ae-9df7-5ef3376e4191",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating lasso regressor instance for pipeline\n",
    "lasso_regressor = LinearRegression(featuresCol = 'features', labelCol='label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "807d47c3-e90d-4229-b42d-63f1846160f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating lasso pipeline \n",
    "lasso_pipeline = Pipeline(stages = [sql_trans_label, scale_trans, encoder_trans, features_Assembler, lasso_regressor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "da61c80d-119a-4bc0-b616-b6632cf350fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating lasso param grid for cross validation - for LASSO eleasticNetParam should be set to 1\n",
    "lasso_paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(lasso_regressor.regParam, [0.01, 0.04, 0.07, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 4.0, 6.0, 10.0, 15.0]) \\\n",
    "    .addGrid(lasso_regressor.elasticNetParam, [1.0]) \\\n",
    "    .build()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae3cc2a-0155-476f-b570-c0bb6a1b4d2d",
   "metadata": {},
   "source": [
    "#### LASSO Cross Validation Using RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ab2cadc6-c360-421c-a875-c307b4be1f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating lasso crossvalidator using the lasso_pipleline, lasso_paramgrid, and using RMSE as our metric\n",
    "lasso_crossval = CrossValidator(estimator = lasso_pipeline,\n",
    "                                estimatorParamMaps = lasso_paramGrid,\n",
    "                                evaluator = RegressionEvaluator(metricName='rmse'),\n",
    "                                numFolds=5,\n",
    "                                seed = 1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6cc45b5f-ca25-40ea-881e-5e5380250e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting model using the lasso cross validator that we created\n",
    "lasso_cv_model = lasso_crossval.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "13f83d4c-8d6b-41ab-bb21-9f4d1344840c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best LASSO Training RMSE: 11.887524127956175\n",
      "Best LASSO Training MAE: 5.212544932916098\n",
      "regParam: regularization parameter (>= 0). (default: 0.0, current: 0.6)\n",
      "\n",
      "Best LASSO RMSE Model coefficients:\n",
      "[0.0,-0.2358422125411112,0.0,0.0,0.0,0.0,1.098019879798396,0.0,0.0,1.1902917349234123,-3.137390878118685,2.726253698394409,3.072749146134405,0.0,0.0,0.0,0.0,1.941462014745174,0.0,29.911172275326905,2.0326926011551776,2.7439072962967916,12.327946908194416,8.625872056097837,1.3813660208620984,0.0,0.0,0.0,0.0,12.294965214782032,0.0,0.0,0.0,-1.0587350435553557,0.0,0.0,0.0,0.0,0.0,0.0,0.6898009870940447,0.0,0.0,-1.2154331037181016,0.0,0.0,-0.346977334243171,0.0,0.0,-0.3878008401784424,0.0,0.0]\n"
     ]
    }
   ],
   "source": [
    "# Lasso model stats\n",
    "best_lasso_Pipeline = lasso_cv_model.bestModel\n",
    "best_lasso_Model = best_lasso_Pipeline.stages[4]\n",
    "print(f\"Best LASSO Training RMSE: {best_lasso_Model.summary.rootMeanSquaredError}\")\n",
    "print(f\"Best LASSO Training MAE: {best_lasso_Model.summary.meanAbsoluteError}\")\n",
    "print(best_lasso_Model.explainParam('regParam'))\n",
    "print(f'\\nBest LASSO RMSE Model coefficients:\\n{best_lasso_Model.coefficients}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de0fd9c-99bd-4a40-a7c3-423f25267676",
   "metadata": {},
   "source": [
    "#### LASSO Cross Validation Using MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "61553af6-3fe0-45e6-8a0f-8e064db6b115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating lasso mae crossvalidator using the lasso_pipleline, lasso_paramgrid, and using MAE as our metric\n",
    "lasso_mae_crossval = CrossValidator(estimator = lasso_pipeline,\n",
    "                                    estimatorParamMaps = lasso_paramGrid,\n",
    "                                    evaluator = RegressionEvaluator(metricName='mae'),\n",
    "                                    numFolds=5,\n",
    "                                    seed = 1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9190d477-1a3a-4960-a0f8-e40638710400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting model using the lasso mae cross validator that we created\n",
    "lasso_mae_cv_model = lasso_mae_crossval.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "474a3067-37fa-49ad-a1ab-e0dedaa87990",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best LASSO MAE Training RMSE: 11.887524127956175\n",
      "Best LASSO MAE Training MAE: 5.212544932916098\n",
      "regParam: regularization parameter (>= 0). (default: 0.0, current: 0.6)\n",
      "\n",
      "Best LASSO MAE Model coefficients:\n",
      "[0.0,-0.2358422125411112,0.0,0.0,0.0,0.0,1.098019879798396,0.0,0.0,1.1902917349234123,-3.137390878118685,2.726253698394409,3.072749146134405,0.0,0.0,0.0,0.0,1.941462014745174,0.0,29.911172275326905,2.0326926011551776,2.7439072962967916,12.327946908194416,8.625872056097837,1.3813660208620984,0.0,0.0,0.0,0.0,12.294965214782032,0.0,0.0,0.0,-1.0587350435553557,0.0,0.0,0.0,0.0,0.0,0.0,0.6898009870940447,0.0,0.0,-1.2154331037181016,0.0,0.0,-0.346977334243171,0.0,0.0,-0.3878008401784424,0.0,0.0]\n"
     ]
    }
   ],
   "source": [
    "# Lasso mae model stats\n",
    "best_lasso_mae_Pipeline = lasso_mae_cv_model.bestModel\n",
    "best_lasso_mae_Model = best_lasso_mae_Pipeline.stages[4]\n",
    "print(f\"Best LASSO MAE Training RMSE: {best_lasso_mae_Model.summary.rootMeanSquaredError}\")\n",
    "print(f\"Best LASSO MAE Training MAE: {best_lasso_mae_Model.summary.meanAbsoluteError}\")\n",
    "print(best_lasso_mae_Model.explainParam('regParam'))\n",
    "print(f'\\nBest LASSO MAE Model coefficients:\\n{best_lasso_mae_Model.coefficients}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3958cb-167d-4ccf-ae95-0a5eb2d9a3ab",
   "metadata": {},
   "source": [
    "Both RMSE and MAE cross validation selected a value of `0.6` for the `regParam` parameter. The resulting models produced were the same."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3845fe-52ec-4333-a991-70abe7936e65",
   "metadata": {},
   "source": [
    "# Model Testing  \n",
    "\n",
    "In this section we will determine the best overall model for predicting the number of absentee hours. We will take each of our five selected models and use them to make predictions on our `test` set. We will then compare them using the model metrics RMSE and MAE to determine the model with the best generalizability and the lowest values for RMSE and MAE on the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d469e69-4e3f-443e-942e-4c02abeb5dec",
   "metadata": {},
   "source": [
    "### Model 1 - MLR  \n",
    "\n",
    "The model selected through cross validation above was a ridge regression model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "bb034b97-dafb-4460-ba22-9c1df3a8a0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using our fitted model from cross validation on our training set to get test error on our test set \n",
    "mlr_pred = mlr_cv_model.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "b6d19610-26e7-45ac-883c-ce6e689e0499",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLR RMSE: 11.819008749039375\n",
      "MLR MAE: 5.132187387597737\n"
     ]
    }
   ],
   "source": [
    "regression_eval = RegressionEvaluator(labelCol = 'label')\n",
    "MLR_rmse = regression_eval.evaluate(mlr_pred, {regression_eval.metricName:'rmse'})\n",
    "MLR_mae = regression_eval.evaluate(mlr_pred,{regression_eval.metricName:'mae'})\n",
    "\n",
    "print(f\"MLR RMSE: {MLR_rmse}\")\n",
    "print(f\"MLR MAE: {MLR_mae}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7771c9c-6750-4687-80fb-75b7cb7c411e",
   "metadata": {},
   "source": [
    "### Model 2 - Regression Tree "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "fedd05cf-074f-44e7-9584-fef47af855d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting predictions for our test set based on the model single regression tree model selected using cv on our training set\n",
    "srt_pred = single_tree_cv_model.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "4603dd8b-a95f-4421-abdb-c55787739169",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single Regression Tree TEST RMSE: 12.86916994105285\n",
      "Single Regression Tree TEST MAE: 5.881674402179398\n"
     ]
    }
   ],
   "source": [
    "srt_rmse = regression_eval.evaluate(srt_pred, {regression_eval.metricName:'rmse'})\n",
    "srt_mae = regression_eval.evaluate(srt_pred,{regression_eval.metricName:'mae'})\n",
    "\n",
    "print(f\"Single Regression Tree TEST RMSE: {srt_rmse}\")\n",
    "print(f\"Single Regression Tree TEST MAE: {srt_mae}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae124f7f-da34-42c7-86cc-977c223618d5",
   "metadata": {},
   "source": [
    "### Model 3 - Random Forest  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "d78f693a-7c0d-4e50-a283-4027758f9c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting predictions for our test set based on the random forest model selected using cv on our training set\n",
    "rf_pred = rf_cv_model.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "199c1495-b98c-4e15-8cbb-6a08b503e42d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest TEST RMSE: 12.14834800677297\n",
      "Random Forest TEST MAE: 5.177339465686892\n"
     ]
    }
   ],
   "source": [
    "rf_rmse = regression_eval.evaluate(rf_pred, {regression_eval.metricName:'rmse'})\n",
    "rf_mae = regression_eval.evaluate(rf_pred,{regression_eval.metricName:'mae'})\n",
    "\n",
    "print(f\"Random Forest TEST RMSE: {rf_rmse}\")\n",
    "print(f\"Random Forest TEST MAE: {rf_mae}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eff1a33-dcdc-47ce-998a-2e2a75eb6761",
   "metadata": {},
   "source": [
    "### Model 4 - Gradient Boosted Regression Tree   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "dc9bda97-5784-44b4-913a-9e1c999b94f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting predictions for our test set based on the boosted regression tree model selected using cv on our training set\n",
    "gbt_pred = gbt_cv_model.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "8d499cad-baad-45a6-bc1b-92a4a428a884",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBT Test  RMSE: 12.700587549568038\n",
      "GBT Test MAE: 5.499868065476387\n"
     ]
    }
   ],
   "source": [
    "gbt_rmse = regression_eval.evaluate(gbt_pred, {regression_eval.metricName:'rmse'})\n",
    "gbt_mae = regression_eval.evaluate(gbt_pred,{regression_eval.metricName:'mae'})\n",
    "\n",
    "print(f\"GBT Test  RMSE: {gbt_rmse}\")\n",
    "print(f\"GBT Test MAE: {gbt_mae}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec4949f-6503-4427-8f86-c370edf65a4a",
   "metadata": {},
   "source": [
    "### Model 5 - LASSO Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "df958f0b-ad58-4b16-967b-c3c1ad76a36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting predictions for our test set based on the LASSO model selected using cv on our training set\n",
    "lasso_pred = lasso_cv_model.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "e419304d-0d91-4552-94b1-cff9c36d64cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso Test  RMSE: 12.045559791956627\n",
      "Lasso Test MAE: 5.092076341968221\n"
     ]
    }
   ],
   "source": [
    "lasso_rmse = regression_eval.evaluate(lasso_pred, {regression_eval.metricName:'rmse'})\n",
    "lasso_mae = regression_eval.evaluate(lasso_pred,{regression_eval.metricName:'mae'})\n",
    "\n",
    "print(f\"Lasso Test  RMSE: {lasso_rmse}\")\n",
    "print(f\"Lasso Test MAE: {lasso_mae}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ca45fd-57ae-4427-853b-6d751dbeccc6",
   "metadata": {},
   "source": [
    "Let's create a dataframe to make comparison of the models a bit easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "c2794a70-08d8-4d03-b3da-b5766aa9cbbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_performance = {'Model':['MLR_Ridge_Regression', 'Single_Regression_Tree', 'Random_Forest', 'Bossted_Tree', 'Lasso_Regression'],\n",
    "                     'RMSE':[MLR_rmse, srt_rmse, rf_rmse, gbt_rmse, lasso_rmse],\n",
    "                     'MAE':[MLR_mae, srt_mae, rf_mae, gbt_mae, lasso_mae]\n",
    "                    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be1195f0-bbf5-40e9-bcc6-b2e98ebf49f8",
   "metadata": {},
   "source": [
    "## Final Model Selection  \n",
    "\n",
    "We can see in the output below that the top two models based on performance on the test set were model 1, the ridge regression model, and model 5, the lasso regression model. Model 1 was the best model when judged by RMSE, while model 5 was the best when compared based on MAE. As discussed earlier, one reason to use RMSE is that it places a heavier penalty on outliers. In this case we will use RMSE as the ultimate measure of model performance and will declare Model 1, the ridge regression model, to be the top performer of the models created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "5581e3d2-9235-4b67-9f5a-adccce90e7a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MLR_Ridge_Regression</td>\n",
       "      <td>11.819009</td>\n",
       "      <td>5.132187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lasso_Regression</td>\n",
       "      <td>12.045560</td>\n",
       "      <td>5.092076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random_Forest</td>\n",
       "      <td>12.148348</td>\n",
       "      <td>5.177339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bossted_Tree</td>\n",
       "      <td>12.700588</td>\n",
       "      <td>5.499868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Single_Regression_Tree</td>\n",
       "      <td>12.869170</td>\n",
       "      <td>5.881674</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Model       RMSE       MAE\n",
       "0    MLR_Ridge_Regression  11.819009  5.132187\n",
       "4        Lasso_Regression  12.045560  5.092076\n",
       "2           Random_Forest  12.148348  5.177339\n",
       "3            Bossted_Tree  12.700588  5.499868\n",
       "1  Single_Regression_Tree  12.869170  5.881674"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(model_performance).sort_values('RMSE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "62106de2-f7b0-429e-8f5d-78d62768adbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lasso_Regression</td>\n",
       "      <td>12.045560</td>\n",
       "      <td>5.092076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MLR_Ridge_Regression</td>\n",
       "      <td>11.819009</td>\n",
       "      <td>5.132187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random_Forest</td>\n",
       "      <td>12.148348</td>\n",
       "      <td>5.177339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bossted_Tree</td>\n",
       "      <td>12.700588</td>\n",
       "      <td>5.499868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Single_Regression_Tree</td>\n",
       "      <td>12.869170</td>\n",
       "      <td>5.881674</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Model       RMSE       MAE\n",
       "4        Lasso_Regression  12.045560  5.092076\n",
       "0    MLR_Ridge_Regression  11.819009  5.132187\n",
       "2           Random_Forest  12.148348  5.177339\n",
       "3            Bossted_Tree  12.700588  5.499868\n",
       "1  Single_Regression_Tree  12.869170  5.881674"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(model_performance).sort_values('MAE')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
